




# 

   'PWMC': module to compute pairwise multiple comparisons (unequal variances)

# 论文推介：借助因果图理解线性交互效应

Kim, Y., & Jung, G. (2024). Understanding linear interaction analysis with causal graphs. British Journal of Mathematical and Statistical Psychology, 78(2), 486–499. Portico. [Link](https://doi.org/10.1111/bmsp.12369), [PDF](https://bpspsychub.onlinelibrary.wiley.com/doi/epdf/10.1111/bmsp.12369), [Google](<https://scholar.google.com/scholar?q=Understanding linear interaction analysis with causal graphs. British Journal of Mathematical and Statistical Psychology, 78(2), 486–499>).

写作时，可以使用如下 AI 工具提供的文本。

- [豆包写的](https://www.doubao.com/thread/w98ee4b3acb70a94d)
- [ChatGPT 写的](https://chatgpt.com/share/68616958-9f2c-8005-a610-e532878f442c)


# Boosting 和 Bagging 的区别

# 机器学习仓库：

> <https://github.com/trekhleb/homemade-machine-learning>

![20250624113140](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250624113140.png)


# Python 练手数据文件汇总

- [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/)
  - [ucimlrepo package](https://github.com/uci-ml-repo/ucimlrepo)

# 论文推介：坏控制变量在DDML中危害很大

- Hünermund, P., Louw, B., & Caspi, I. (2023). Double machine learning and automated confounder selection: A cautionary tale. Journal of Causal Inference, 11(1). [Link](https://doi.org/10.1515/jci-2022-0078), [PDF](https://www.degruyterbrill.com/document/doi/10.1515/jci-2022-0078/pdf?licenseType=open-access), [Google](<https://scholar.google.com/scholar?q=Double machine learning and automated confounder selection: A cautionary tale>).

# 论文推介：

Doutreligne, M., & Varoquaux, G. (2025). How to select predictive models for decision-making or causal inference. GigaScience, 14. [Link](https://doi.org/10.1093/gigascience/giaf016), [PDF](https://watermark.silverchair.com/giaf016.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA4wwggOIBgkqhkiG9w0BBwagggN5MIIDdQIBADCCA24GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM5iM9hkWQtZwwhEvAAgEQgIIDP2lzki5fhc6qB4FaN5dNPiJ0zrcWlirsiNlmzzdM8NmFaloGHJxWixIRd7WH4F8jM9YlldyPhp853Mcmi6hduXDsgnUjwa1FhAcItT3hZLJRBqGBsnxj2IQnu2YhyOPadEvCIbt6R07PLMAV8wPR0ZbdQvURdbjhf3LwdaaCNewGQpDSGPVFNsdOTusbuFAUjV62E0gy0t75qox7gji477WQ0RsGQ-t-PYh2EsR8e_s9kEt3xytLIAF66AtJyWpbJzac3XIywJ-mZAmBQZNyMvl0JZpffV1ZiGJm47PwEwB8F5iLsFNcoIr3RyNpUD_vQNw9FMEWRnrT848VAHqDoidfXXIUcmkAOfCWvuVzpbOvaWVBqq_9oaqnuHKYCw_k-WbAlFlNCrrvTfKdu-CzdxvuSkuXRQu7KC-qgF3s0tL2eerj_e_VEUyApw790MQkriG3YqukwXTo1t_QryulKlvh7rUcYgYzwshv89BTRKDPlJilMrUvDD7bXDCDWcoUKNqfisXHXexrh9MMq5KooSXgU_1FpT2fb9C5c8KG5o7WGBHqHL-XexGdWQON6_j_o7s8x6idZPabPiGD0DzHey8PZ-xmnLK9hUsXfFAEoyqGL7aBxUkgSTz1zKA6JOpBVcRKEMWmKhmdkzdluShOFDoZ26KGk0id2zYLMhoz6xlLs2G84CHeEnbkh9Sl-PkI_AL0OBylmsZ5bZptaa6Du0_SxVwuqVH1CD30pakQROp9_GMkRBoiavmfrj6JteDozj33JMH-6zocfENEMhxtfM8WOrSPIZ5fUoqUHFnUsTe20LHwmT_NmEV9CiN5bPMxrURzBfilQ-ern-RJItZAaNzd5H1AON4cQo5u2xVdfXUwxWFzXV_89tgXZnRxdX7-cGBAFHGdCMFvld-BUi1_yqDOjO1uRp9PNhqklg0S1X2xy0PeN49b6HpzBMMQENEpWcx7ffGZViaKH6aDHyj1cKbW0Im_4YJorns0HBvKRwrOB273jNmicGgEVUN1dIIc8QGIdbGz-fCqOhLJHrO0uUCPvldSyExIjVQdvPvLlvx4CAF7O_Spvhsqbrdv4HG5_z-QNV66NzSnxSM_YDpj3A), [Google](<https://scholar.google.com/scholar?q=How to select predictive models for decision-making or causal inference>).

# 论文推介：DDML简介

Ahrens, A., Chernozhukov, V., Hansen, C., Kozbur, D., Schaffer, M., & Wiemann, T. (2025). An Introduction to Double/Debiased Machine Learning. arXiv. [Link](https://doi.org/10.48550/arXiv.2504.08324) (rep), [PDF](https://arxiv.org/pdf/2504.08324.pdf), [Google](<https://scholar.google.com/scholar?q=An Introduction to Double/Debiased Machine Learning (Version 1)>).

# 论文复现+中文精要：R codes

> 这是三篇推文的工作量

- D’haultfœuille, X., Gaillac, C., & Maurel, A. (2025). Partially Linear Models under Data Combination. Review of Economic Studies, 92(1), 238–267. [Link](https://doi.org/10.1093/restud/rdae022) (rep), [PDF](http://sci-hub.ren/10.1093/restud/rdae022), [Google](<https://scholar.google.com/scholar?q=Partially Linear Models under Data Combination>). [-Replication-](https://zenodo.org/records/10230839) 

  - 我们研究了部分线性模型中结果变量与部分协变量分属两个独立数据集（无法匹配）的情况，这类数据组合问题在实证微观经济学中十分常见。借助最优传输理论的最新工具，我们对尖锐识别集进行了构造性刻画，并据此开发了一种新的推断方法。该方法利用识别集的几何特性，在有限样本下表现良好且易于操作。我们将此方法应用于1850-1930年美国代际收入流动性研究，结果显示：相比以往研究，新方法放宽了排他性约束，同时能给出有效置信区间。这种框架为跨数据集因果推断提供了实用方案，尤其适用于因数据隐私等限制无法合并数据集的场景。

# Statistical control requires causal justification

- Wysocki, A. C., Lawson, K. M., & Rhemtulla, M. (2022). Statistical Control Requires Causal Justification. Advances in Methods and Practices in Psychological Science, 5(2). [Link](https://doi.org/10.1177/25152459221095823), [PDF](https://journals.sagepub.com/doi/epdf/10.1177/25152459221095823), [Google](<https://scholar.google.com/scholar?q=Statistical Control Requires Causal Justification>).

  - 在相关研究或准实验研究中，常见的做法是通过统计控制消除回归系数中的混杂效应。控制相关混杂因素能够消除预测变量对结果变量的因果效应估计偏差——即令回归系数估计值更接近真实因果效应值。但统计控制仅在理想条件下有效。当选取的控制变量不恰当时，控制操作反而可能导致比未控制时更大的估计偏差。尽管统计控制在已发表的回归分析中普遍存在，且控制不恰当的第三方变量会产生严重后果，但控制变量的选择依据在文献中却很少明确说明。我们主张：研究者必须提出并论证包含结果变量、预测变量及潜在混杂因素的因果结构框架，才能严谨地选取合适的控制变量。通过演示回归系数如何因控制恰当/不恰当变量而产生变化，我们强调了因果性在控制变量选择中的核心地位。最后，为希望采用统计控制方法的实践研究者提供了具体建议。

# 面板数据的使用

- Cerqua, A., Letta, M., & Pinto, G. (2024). On the (Mis)Use of Machine Learning with Panel Data (Version 2). arXiv. [Link](https://doi.org/10.48550/arXiv.2411.09218) (rep), [PDF](https://arxiv.org/pdf/2411.09218.pdf), [Google](<https://scholar.google.com/scholar?q=On the (Mis)Use of Machine Learning with Panel Data (Version 2)>). [github](https://github.com/gabrielepinto/results_ml_replication), [ML_analysis_panel_data_replication.ipynb](https://github.com/gabrielepinto/results_ml_replication/blob/main/ML_analysis_panel_data_replication.ipynb)

# 

Frey, E. (2024). How to cross-validate your panel data in Python. Towards Data Science. Available
at : https://github.com/4Freye/panelsplit.

# staggered

- <https://psantanna.com/files/Roth_SantAnna_Staggered.pdf>
- <https://github.com/mcaceresb/stata-staggered>

# R package: unitdid

The `unitdid` package provides a set of functions for the analysis of the unit-level event studies (ULES) ([Arkhangelsky, Yanagimoto, and Zohar 2024](https://arxiv.org/abs/2403.19563)).

- Arkhangelsky, D., Yanagimoto, K., & Zohar, T. (2024). On Causal Inference with Model-Based Outcomes (Version 3). arXiv. [Link](https://doi.org/10.48550/arXiv.2403.19563) (rep), [PDF](https://arxiv.org/pdf/2403.19563.pdf), [Google](<https://scholar.google.com/scholar?q=On Causal Inference with Model-Based Outcomes (Version 3)>).
- R codes: <https://kazuyanagimoto.com/unitdid/>
- https://github.com/kazuyanagimoto/unitdid/
- https://tomzohar.com/assets/writeups/unitdid.pdf

# ecic：Extended changes-in-changes

- https://github.com/frederickluser/ecic
- frederickluser.github.io/ecic/


# 小样本下的DID统计推断问题

Mizushima, Yuji and Powell, David, Inference with Modern Difference-in-Differences Methods (April 04, 2025). Available at SSRN: https://ssrn.com/abstract=5221387 or http://dx.doi.org/10.2139/ssrn.5221387

### Abstract

Several new difference-in-differences (DiD) estimators address biases arising from staggered adoption and heterogeneous treatment effects. The reliability of the standard errors of these methods is understudied, particularly in settings with few treated units. This paper examines the finite-sample performance of seven leading DiD estimators under various simulated conditions. Most estimators tend to over-reject when the number of treated units is small. Treatment heterogeneity induces its own bias, reducing rejection rates. An imputation-based estimator paired with a wild bootstrap performs well across simulation designs, maintaining rejection rates close to nominal levels when there is treatment homogeneity and providing conservative inference otherwise.

**Keywords:** Difference-in-Differences, Wild Bootstrap, Finite Inference

# Python-pyfixest：

- Lal, A. (2025). When can we get away with using the two-way fixed effects regression? (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2503.05125) (rep), [PDF](https://arxiv.org/pdf/2503.05125.pdf), [Google](<https://scholar.google.com/scholar?q=When can we get away with using the two-way fixed effects regression? (Version 1)>).
  - The use of the two-way fixed effects regression in empirical social science was historically motivated by folk wisdom that it uncovers the Average Treatment effect on the Treated (ATT) as in the canonical two-period two-group case. This belief has come under scrutiny recently due to recent results in applied econometrics showing that it fails to uncover meaningful averages of heterogeneous treatment effects in the presence of effect heterogeneity over time and across adoption cohorts, and several heterogeneity-robust alternatives have been proposed. However, these estimators often have higher variance and are therefore under-powered for many applications, which poses a bias-variance tradeoff that is challenging for researchers to navigate. In this paper, we propose simple tests of linear restrictions that can be used to test for differences in dynamic treatment effects over cohorts, which allows us to test for when the two-way fixed effects regression is likely to yield biased estimates of the ATT. These tests are implemented as methods in the pyfixest python library.
- Python 实现：
  - [Getting Started with PyFixest](https://py-econometrics.github.io/pyfixest/quickstart.html)
  - [github-pyfixest](https://github.com/py-econometrics/pyfixest)


# Python仓库介绍：pyfixest

- [py-econometrics/pyfixest](https://github.com/py-econometrics/pyfixest), [website](https://py-econometrics.github.io/pyfixest/pyfixest.html)


# 翻译+适当补充：Tidy Fixed Effects Regressions: fixest vs pyfixest

- [Tidy Fixed Effects Regressions: fixest vs pyfixest](https://blog.tidy-intelligence.com/posts/fixed-effects-regressions/)


# 翻译：Interactive Data Visualization with Python

- [Interactive Data Visualization with Python](https://blog.tidy-intelligence.com/posts/interactive-data-visualization-with-python/)


# python-wildboottest

- [python module for wild cluster bootstrapping](https://github.com/py-econometrics/wildboottest)
- [website](https://py-econometrics.github.io/wildboottest/)

# R包推荐：wildrwolf

Romano-Wolf p-value adjustments for multiple hypotheses testing via the wild bootstrap for objects of type `fixest` and `fixest_multi` from the `fixest` package

[s3alfisc.github.io/wildrwolf/](https://s3alfisc.github.io/wildrwolf/ "https://s3alfisc.github.io/wildrwolf/")
- <https://github.com/s3alfisc/wildrwolf>

# MachineControl

### Causal inference and policy evaluation without a control group

##### *[Augusto Cerqua](https://flore.unifi.it/cris/rp/rp156520);[Marco Letta](https://flore.unifi.it/cris/rp/rp156460);[Fiammetta Menchetti](https://flore.unifi.it/cris/rp/rp08886)*


#### Abstract

Without a control group, the most widespread methodologies for estimating causal effects cannot be applied. To fill this gap, we propose the Machine Learning Control Method, a new approach for causal panel analysis that estimates causal parameters without relying on untreated units. We formalize identification within the potential outcomes framework and then provide estimation based on machine learning algorithms. To illustrate the practical relevance of our method, we present simulation evidence, a replication study, and an empirical application on the impact of the COVID-19 crisis on educational inequality. We implement the proposed approach in the companion R package MachineControl.

https://flore.unifi.it/handle/2158/1407495

- R package: `MachineControl`



# 综述：

- Arkhangelsky, D., & Imbens, G. (2024). Causal models for longitudinal and panel data: a survey. The Econometrics Journal, 27(3), C1–C61. [Link](https://doi.org/10.1093/ectj/utae014), [-PDF-](https://watermark.silverchair.com/utae014.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA2EwggNdBgkqhkiG9w0BBwagggNOMIIDSgIBADCCA0MGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMrICHONYKZauEOih9AgEQgIIDFFTpoGkt84ZKBQlGFNU_7QK0oJzFvGb2wLU2XbzOd7Z3Gei2ebqmYH-BiZKyi3NkHu3kgvHzSp16mjM_9u0n8dO9ob-gLd5zefsyZnmL_KJdlQjjzaXX1k-WHwnKKnd2Tv4VL34yszUGIXXsKqXdAVmq4ZUDK_zkoqwiqnJIIra6jh7f8K0Sx1cjxEtN8NB_bfw3oMeQKd7hDmNqU0rtTeT954VL8asI_HGWkqI1zNMicFoL2bevaoqMig9hwhc39rpX4sdEnbtl7St8joZJHyfGFx81AlhqFfrW3LEmTrN3CL3BL_gIJRpeaIZR5NBJwob6Re1lkDnmYzYi4X1ow6FRnLA2qKLnla9rma62Xp3__tRFOZmUEWXdvLgk0iKNwdx3pFP9VhMqlHSg4TD78gbvRavPgNO2X9nP0mVQ5tp9Vd7VJ3-WncPGShT3KwawA2jD7hibjji8HICJfISPdMNPnT7nPekpWTJjm1wszcQyoRyhVzaCr3AevP7xWOLJuFmQFldbGm_nAcfW5SxWL3-vNIXPQnYgAlio6tOL11W7rMUjqchc0amgPtD5URTuio5Znx6ibB0DUBsm_yL5KE5xWChCgRfaHZbPgvHLZ3yCSdV0K943N_cKouNhXbBQMb32q8k7SemARSASFBoKVuZlyXCuqitSJ2W3Vk9NxcTTVxPaftv0j4rdBe9y8NorRh0wOsJjva5nPRtacBBoLzZHrBIcMIyAEt8rVPa8W55bRzqYv6etKqj3VtOSPS29x5OFJIJ-VwqsX0B94tBY1JXiJR1oQdTyeymTHAEI6HcDME3rneYxQf2n82aMoJq99c_WVgFk1ns1YVRbsxTBhSe0a66JQG-V1LcIdyujuOvvycPBlLMRKkkVSno1z5jbZrutlDOZg7wArK-UQ5kfMf55N3jVxO74OMLCSYK6-wWqC05Ltbicx3sOsc6rrEcYPVf3mWvibGR_xGlAg6ThV2SmL-XFTeBPPD0ul80j13VddwnM6onyf0zYHmeGuYWmo1QEjWYeKbd_H3vX5COm-OyD5433), [Google](<https://scholar.google.com/scholar?q=Causal models for longitudinal and panel data: a survey>).

# 新书推荐：

- Wager, Stefan. 2024, Causal Inference: A Statistical Learning Approach. [-PDF-](https://web.stanford.edu/~swager/causal_inf_book.pdf)


# ivbounds：

Lin, A., Tommasi, D., & Zhang, L. (2024). Bounding program benefits when participation is misreported: Estimation and inference with Stata. The Stata Journal, 24(2), 185–212. [Link](https://journals.sagepub.com/doi/10.1177/1536867X241257347), [PDF](https://journals.sagepub.com/doi/pdf/10.1177/1536867X241257347), [Google](<https://scholar.google.com/scholar?q=Bounding program benefits when participation is misreported: Estimation and inference with Stata>).

- Abstract: Instrumental-variables estimation is an approach commonly used to evaluate the effect of a program in case of noncompliance. However, when the binary treatment status is misreported, standard techniques are not sufficient to point identify and consistently estimate the effect of interest. We present a new command, ivbounds, that implements three partial identification strategies developed by Tommasi and Zhang (2024, Journal of Econometrics 238: 105556) to bound the heterogeneous treatment effect when both noncompliance and misreporting of treatment status are present. We illustrate the use of the command by reassessing the benefits of participating in the 401k pension plan on savings in the United States.

## 参考文献

- Kline, B., & Tamer, E. (2023). Recent Developments in Partial Identification. Annual Review of Economics, 15(1), 125–150. [Link](https://doi.org/10.1146/annurev-economics-051520-021124), [PDF](http://sci-hub.ren/10.1146/annurev-economics-051520-021124), [Google](<https://scholar.google.com/scholar?q=Recent Developments in Partial Identification>).

# 新书推介：

**Papadopoulos, A.**, & Parmeter, C. F. (2025). Two-Tier Stochastic Frontier Analysis for the Social Sciences. Springer Nature Switzerland. [Link](https://doi.org/10.1007/978-3-031-81513-3), [PDF](https://link.springer.com/content/pdf/10.1007/978-3-031-81513-3.pdf), [Google](<https://scholar.google.com/scholar?q=Two-Tier Stochastic Frontier Analysis for the Social Sciences>), [github](https://github.com/Parms23/2TSF)

# 论文推介：双边随机边界模型
Lian, Y., Liu, C., & Parmeter, C. F. (2023). Two-tier stochastic frontier analysis using Stata. Stata Journal, 23(1), 197–229. [Link](https://doi.org/10.1177/1536867X231162033), [PDF](https://file.lianxh.cn/Refs/LianPub/Lian-2023-SJ-sftt-Two-tier-SFA.pdf), [Codes & Data](https://gitee.com/arlionn/sftt), [github](https://github.com/arlionn/sftt)

该文的相关评论，可以从如下书籍中的摘取：

**Papadopoulos, A.**, & Parmeter, C. F. (2025). Two-Tier Stochastic Frontier Analysis for the Social Sciences. Springer Nature Switzerland. [Link](https://doi.org/10.1007/978-3-031-81513-3), [PDF](https://link.springer.com/content/pdf/10.1007/978-3-031-81513-3.pdf), [Google](<https://scholar.google.com/scholar?q=Two-Tier Stochastic Frontier Analysis for the Social Sciences>), [github](https://github.com/Parms23/2TSF)

## 为何会有两个随机边界

参见 Papadopoulos & Parmeter ([2025](https://doi.org/10.1007/978-3-031-81513-3))「1.3 Why Would There Be Two Frontiers?」

## Stata 实操

```stata
ssc install sftt, replace all
```





# R包推荐：causalQual-定性结果的因果推断

Di Francesco, R., & Mellace, G. (2025). Causal Inference for Qualitative Outcomes. arXiv. [Link](https://doi.org/10.48550/arXiv.2502.11691) (rep), [PDF](https://arxiv.org/pdf/2502.11691.pdf), [Google](<https://scholar.google.com/scholar?q=Causal Inference for Qualitative Outcomes (Version 1)>), [github](https://github.com/riccardo-df/causalQual), [Website](https://riccardo-df.github.io/causalQual/)

- 因果推断方法，如工具变量法、回归不连续性设计和差异中的差异，广泛应用于估计处理效应。然而，当这些方法用于定性结果时，会面临一些根本性挑战，因为在这种情况下，标准的因果估计量无法清晰定义。本文探讨了这些问题，并提出了一种替代框架，重点关注那些既明确又易于解释的估计量，旨在衡量处理如何影响结果类别的概率分布。我们证明了标准的识别假设足以保证因果效应的识别，并提出了简单、直观的估计策略，这些策略与传统的计量经济学方法兼容。为了便于应用，我们提供了一个开源R包——`causalQual`，已经在 [github](https://github.com/riccardo-df/causalQual) 上公开。

`causalQual` 包提供了一整套工具，用于在处理定性结果时估计因果效应（例如，多项选择或有序结果）。

传统的因果推断方法，如工具变量法（IV）、回归不连续性设计（RD）和倍分法（DiD），通常是为数值型结果设计的。当这些方法直接应用于定性结果时，往往会导致估计量定义不清，从而使得结果变得不明确且难以解释。

该包实现了 Di Francesco 和 Mellace（2025）提出的框架，聚焦于那些定义明确、易于解释的估计量，量化处理如何影响结果类别的概率分布。这些方法与传统的研究设计兼容，简化了应用研究者的操作过程。


Why use `causalQual`?
---------------------

| Feature                             | Benefit                                                                                                                                        |
| ----------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |
| **Avoids misleading conclusions**   | Conventional estimands are often undefined or depend on arbitrary outcome coding. `causalQual` targets interpretable and meaningful estimands. |
| ---                                 | ---                                                                                                                                            |
| **Provides well-defined estimands** | Instead of relying on average effects, `causalQual` models how treatment shifts probabilities over outcome categories.                         |
| **Wide applicability**              | Supports selection-on-observables, IV, RD, and DiD.                                                                                            |
| **Extensible and open-source**      | Actively developed with planned support for staggered adoption, fuzzy regression discontinuity, and more.                                      |

## R 实操

……

# 论文推介：

重点是该文的建议，即 Section 5. Recommendations for practice

Mogstad, M., & Torgovitsky, A. (2024). Instrumental variables with unobserved heterogeneity in treatment effects. Handbook of Labor Economics, 1–114. [Link](https://doi.org/10.1016/bs.heslab.2024.11.003), [PDF](http://sci-hub.ren/10.1016/bs.heslab.2024.11.003), [Google](<https://scholar.google.com/scholar?q=Instrumental variables with unobserved heterogeneity in treatment effects>). [-PDF-](https://download.ssrn.com/23/04/30/ssrn_id4433503_code1300406.pdf?response-content-disposition=inline&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEKj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCICYJHTcTQCJYYTKyveV9w3bN2kMiLV91mvUcCMmP9c8BAiBFJdsDvThtdRiAE7lnFsx5KYEv08xmCiG3VyLDpOMpqirFBQiR%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAQaDDMwODQ3NTMwMTI1NyIMWAzErqG9y2vp%2BGl%2BKpkFn%2F8UHmh%2FG8IXvZGeiuQ057T%2F%2BQGx3C6B2aHrBqjdT4ufw1QrIvgi18LSx96Ci8d5YfFmqrEZYd%2Fn8pECsie1%2BZiUyukuJcnrabQJli93AXqumWFMLy%2FPKXWSDfvgZj44O7DZjXHG5icIzKIiV3W%2FGxrl9jvBc2unIOyuj7I2KzSjlQEcEIn6R5I1XloaLICnrSCzFgu9zAWF118P5eKIGgO0wG%2FWII%2FsBBxL5%2BBBNdzPdhqYZP6NrH0ALOJKjfYn3FW5FR7MXVo%2B4GWVgSUNmp4MG52m0g7XVE%2BvR4M4bVA7uFvXsOgVCJQmvoQd2XCKVNyaN9wN6s0zGJO1gRBUUsUNy51%2FqPv54GO520ETiUF%2FILGPr8TzcYz4%2BLZEm2szzB1s3yYz9c%2FTtogxOvcs8NZwturEl6Rtb%2BvPZ%2Fu6wWqZ7jjg7Mqg1UEzUY0hlug2XrUtFDsaKEje0AIz%2FHFL1KTEr%2F8M2IOINRhrLnDtIzJWz4OLt0YecAhG1vZ92D1CiD%2B975IgpVqJbQAtgemgix%2Fu8UStWfGVLUgH4AF7btUMDJCOceQjzUO4pHwv7QtSBjbwQ9uwkslPplJqvIjCTXRK3w2ZsPjgnvzV5wr%2FoyZ0D4FIdvdgdJeIsnv%2FZ3iyYUsvF3nvTKIWlS3ho1AkHUrSV2tM5aKV2IUdRlfHue24ozNB4HtOr7SZNhhWWnajRaWQr3WEtmLvByZg634XRsnnHDgc5z0sjc3Lso3Z0uzyTeT4GmIPkQ%2FgWIGyi4r4Vs3HJKmgT9qF6pj%2FhXR6FNKY9ifeZFYUQsWQk6SAOAocdEjL0S07y8LZE6iaf%2FZjdGF8qHDJYwiuLwlT9rlVce1jcsfxUZziFCXdRmWHJpyDBkXfhYQ3S6ww1b3LwgY6sgEQww68kBbp2pKpd1ZEdDiNpDn7G1BDilpLfoSosiWwF%2FkwRYEp1Ebm%2FUlYhxMfi%2Bgl95csVgJdTUSamNNA2U56uU44qkiNcHKMuFGriwxdvOLqp4yK819FPkkWCAFg6g5itqCPd2bDo2wsfS8GmeU8JDjRB%2Bt3GGwOcDEbSIXj%2BwYSHcCukxZhnB4phW3gJk8JKcGrZbjUK1UctDqya5FmOmX2nJvZXkSr%2Bpfw9qg%2Fi2C6&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250618T164710Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAUPUUPRWE32GN6MAW%2F20250618%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=7958854f1d8456f32c82a0787161f2c6bce0a6797efa2daee54c75c0bcd73552&abstractId=4433503)


# aggTrees：Aggregation Trees

- Di Francesco, R. (2024). Aggregation Trees. arXiv. [Link](https://doi.org/10.48550/arXiv.2410.11408) (rep), [PDF](https://arxiv.org/pdf/2410.11408.pdf), [Google](<https://scholar.google.com/scholar?q=Aggregation Trees (Version 1)>), [github](), [Website](https://riccardo-df.github.io/aggTrees/), [Tutorial](https://riccardo-df.github.io/aggTrees/articles/aggTrees-vignette.html)


# valiCATE

https://riccardo-df.github.io/valiCATE/articles/valiCATE-short-tutorial.html

- 可视化：<https://riccardo-df.github.io/valiCATE/articles/more-on-plotting.html>

# 诺奖演讲推介

Angrist, J. D. (2022). Empirical Strategies in Economics: Illuminating the Path From Cause to Effect. Econometrica, 90(6), 2509–2539. [Link](https://doi.org/10.3982/ECTA20640) (rep), [PDF](http://sci-hub.ren/10.3982/ECTA20640), [Google](<https://scholar.google.com/scholar?q=Empirical Strategies in Economics: Illuminating the Path From Cause to Effect>).

# Causal ML

Zhao, Y., & Liu, Q. (2023). Causal ML: Python package for causal inference machine learning. SoftwareX, 21, 101294. [Link](https://doi.org/10.1016/j.softx.2022.101294), [PDF](http://sci-hub.ren/10.1016/j.softx.2022.101294), [Google](<https://scholar.google.com/scholar?q=Causal ML: Python package for causal inference machine learning>).

# causal-learn

翻译+酌情补充：

Zheng, Y., Huang, B., Chen, W., Ramsey, J., Gong, M., Cai, R., Shimizu, S., Spirtes, P., & Zhang, K. (2024). Causal-learn: Causal discovery in python. Journal of Machine Learning Research, 25(60), 1-8.


Causal Discovery in Python. It also includes (conditional) independence tests and score functions.

[causal-learn.readthedocs.io/en/latest/](https://causal-learn.readthedocs.io/en/latest/)

- [github](https://github.com/py-why/causal-learn)



# DoWhy：Python 仓库介绍

- [github](https://github.com/py-why/dowhy)

![20250619000930](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250619000930.png)

`DoWhy` is a Python library for causal inference that supports explicit modeling and testing of causal assumptions. `DoWhy` is based on a unified language for causal inference, combining causal graphical models and potential outcomes frameworks.

## [Checkout the documentation](https://py-why.github.io/dowhy/)

-   The documentation, user guide, sample notebooks and other information are available at

    [https://py-why.github.io/dowhy](https://py-why.github.io/dowhy/)

-   DoWhy is part of the [PyWhy Ecosystem](https://www.pywhy.org/). For more tools and libraries related to causality, checkout the [PyWhy GitHub organization](https://github.com/py-why/)!
-   For any questions, comments, or discussions about specific use cases, join our community on [Discord](https://discord.gg/cSBGb3vsZb) ([![discord](https://camo.githubusercontent.com/b32b103b53c60888ed9606a1ce38d9864949cb1c0a1d7c94796d7b01b6e33c99/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f383138343536383437353531313638353432)](https://discord.gg/cSBGb3vsZb))
-   Jump right into some case studies:

    -   Effect estimation: [Hotel booking cancellations](https://towardsdatascience.com/beyond-predictive-models-the-causal-story-behind-hotel-booking-cancellations-d29e8558cbaf) | [Effect of customer loyalty programs](https://www.pywhy.org/dowhy/main/example_notebooks/dowhy_example_effect_of_memberrewards_program.html) | [Optimizing article headlines](https://medium.com/@akelleh/introducing-the-do-sampler-for-causal-inference-a3296ea9e78d) | [Effect of home visits on infant health (IHDP)](https://towardsdatascience.com/implementing-causal-inference-a-key-step-towards-agi-de2cde8ea599) | [Causes of customer churn/attrition](https://medium.com/geekculture/a-quickstart-for-causal-analysis-decision-making-with-dowhy-2ce2d4d1efa9)
    -   Root cause analysis and explanations: [Causal attribution and root-cause analysis of an online shop](https://www.pywhy.org/dowhy/main/example_notebooks/gcm_online_shop.html) | [Finding the Root Cause of Elevated Latencies in a Microservice Architecture](https://www.pywhy.org/dowhy/main/example_notebooks/gcm_rca_microservice_architecture.html) | [Finding Root Causes of Changes in a Supply Chain](https://www.pywhy.org/dowhy/main/example_notebooks/gcm_supply_chain_dist_change.html)

For more example notebooks, see [here!](https://www.pywhy.org/dowhy/main/example_notebooks/nb_index.html)

# causal mediation analysis

Liu, R., Williams, N. T., Rudolph, K. E., & Díaz, I. (2024). General targeted machine learning for modern causal mediation analysis (Version 2). arXiv. [Link](https://doi.org/10.48550/arXiv.2408.14620) (rep), [PDF](https://arxiv.org/pdf/2408.14620.pdf), [Google](<https://scholar.google.com/scholar?q=General targeted machine learning for modern causal mediation analysis (Version 2)>).

# medoutcon

- What's medoutcon?
- [github](https://github.com/nhejazi/medoutcon)

The medoutcon R package provides facilities for efficient estimation of path-specific (in)direct effects that measure the impact of a treatment variable $A$ on an outcome variable $Y$, through a direct path (through $A$ only) and an indirect path (through a set of mediators $M$ only). In the presence of an intermediate mediator-outcome confounder $Z$, itself affected by the treatment $A$, these correspond to the interventional (in)direct effects described by Diaz et al. (2020), though similar (yet less general) effect definitions and/or estimation strategies have appeared in VanderWeele, Vansteelandt, and Robins (2014), Rudolph et al. (2017), Zheng and van der Laan (2017), and Benkeser and Ran (2021). When no intermediate confounders are present, these effect definitions simplify to the well-studied natural (in)direct effects, and our estimators are analogs of those formulated by Zheng and van der Laan (2012). Both an efficient onestep bias-corrected estimator with cross-fitting (Pfanzagl and Wefelmeyer 1985; Zheng and van der Laan 2011; Chernozhukov et al. 2018) and a cross-validated targeted minimum loss estimator (TMLE) (van der Laan and Rose 2011; Zheng and van der Laan 2011) are made available. medoutcon integrates with the sl3 R package (Coyle et al. 2021) to leverage statistical machine learning in the estimation procedure.

# 基于 DDML 的中介效应分析-连续变量

- Double Debiased Machine Learning for Mediation Analysis with Continuous Treatments
- [github](https://github.com/houssamzenati/double-debiased-machine-learning-mediation-continuous-treatments)

# Package ‘causalweight’
March 26, 2025

- Title: Estimation Methods for Causal Inference Based on Inverse Probability Weighting and Doubly Robust Estimation
- [-PDF-](https://cran.r-project.org/web/packages/causalweight/causalweight.pdf)

# medDML: Causal mediation analysis with double machine learning

- <>

# 论文推介：实证研究的未来和挑战

Otsuka, K., Higuchi, Y., Suzuki, A. (2024). Challenges in Empirical Research in Economics: The Way Forward. In: Otsuka, K., Kurosaki, T., Sawada, Y., Sonobe, T. (eds) Next-Generation of Empirical Research in Economics. Springer, Singapore. [-Link-](https://doi.org/10.1007/978-981-97-1887-0_4), [-PDF-](https://link.springer.com/content/pdf/10.1007/978-981-97-1887-0.pdf)



毫无疑问，随机对照试验（RCT）和自然实验（NE）作为识别因果关系的估计方法，是可靠的。在未来的经济学实证研究中，采用这些方法的研究有望占据重要位置。这些方法将占据何种重要位置，取决于它们解答的研究问题的意义。既然识别因果效应的技术已经得到建立，那么研究主题的选择将变得尤为重要。

根据作者的经验，传统的观察性研究通常按以下步骤进行：研究者从文献综述中选择看似重要的主题，进行初步调查以了解现实情况，设定研究问题，并确定分析的方向。在这一阶段，分析的最终结果尚不可知，研究主题仍有可能进行修改。因此，观察性研究允许研究者探索尚未解决的问题。然而，对于RCT和NE，研究者在选题阶段就必须预测结果，因为在数据收集之前，需要考虑识别方法和RCT设计。如果没有选择一个合适的主题，大规模实验或大量数据收集可能会得出无意义的结果。特别是如果进行RCT时没有充分理解当地的实际情况，失败的风险会很高。为了避免这种情况，了解领域现实、掌握经济学理论和计量经济学技巧，对于选择一个合适的研究主题至关重要。

然而，具备所有所需技能的研究者非常少见。例如，很少有研究者能够同时掌握流行病学知识、了解非洲驱虫药物的疗效、基于经济学理论考虑外部性，并且能够运用恰当的计量经济学方法进行所有估计。因此，正如表4.2所示，合著者的数量正在不断增加，预计那些具备深厚领域理解、扎实经济学理论基础和计量经济学技能的研究者之间的联合研究将变得越来越重要。然而，完备的分工合作并非易事。如果不同专业背景的研究者共同合作，由于信息不对称，他们可能无法互相评估彼此的工作成果，甚至产生怀疑，这可能导致合作研究的失败。因此，只有当合著者能够理解彼此的努力和贡献时，知识共享才是联合研究成功的前提。

从这个角度来看，未来有效使用RCT和NE的门槛可能会越来越高。特别是大规模的RCT对于资源有限的年轻研究者来说，既昂贵又具有相当的负担。在这种情况下，使用二手数据且应用范围更广的NE方法可能会变得更加重要。

# 会计领域的研究中贝叶斯推断的应用
Schütt, H. H. (2023). What Can Bayesian Inference Do for Accounting Research? Journal of Financial Reporting, 8(2), 157–174. [Link](https://doi.org/10.2308/JFR-2021-002), [PDF](http://sci-hub.ren/10.2308/JFR-2021-002), [Google](<https://scholar.google.com/scholar?q=What Can Bayesian Inference Do for Accounting Research>).****


# beyond p<0.05: 

- Kallapur, Sanjay, Beyond P<0.05: Scientific Inference in Accounting Research (December 7, 2022). Studies in Accounting Research #34, American Accounting Association, Available at SSRN: https://ssrn.com/abstract=4413565 or http://dx.doi.org/10.2139/ssrn.4413565, [-PDF-](https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID4413565_code65388.pdf?abstractid=4413565&mirid=1&type=2)

## 参考文献

- Kallapur, Sanjay. 2022. *Beyond P<0.05: Scientific Inference in Accounting Research. Studies in Accounting Research*, Vol. *34*. Sarasota: American Accounting Association.[10.2139/ssrn.4413565](https://doi.org/10.2139/ssrn.4413565)[Search in Google Scholar](https://scholar.google.com/scholar?q=Kallapur%2C%20Sanjay.%202022.%20Beyond%20P%3C0.05%3A%20Scientific%20Inference%20in%20Accounting%20Research.%20Studies%20in%20Accounting%20Research%20%2C%20Vol.%C2%A0%2034%20.%20Sarasota%3A%20American%20Accounting%20Association.)

- Leuz, Christian. 2022. "Towards a Design-Based Approach to Accounting Research." *Journal of Accounting and Economics* *74* (2): 101550. <https://doi.org/10.1016/j.jacceco.2022.101550>.[Search in Google Scholar](https://scholar.google.com/scholar?q=Leuz%2C%20Christian.%202022.%20%E2%80%9CTowards%20a%20Design-Based%20Approach%20to%20Accounting%20Research.%E2%80%9D%20Journal%20of%20Accounting%20and%20Economics%2074%20%282%29%3A%20101550.%20.)
Schütt, Harm H. 2023. "What Can Bayesian Inference Do for Accounting Research?" *Journal of Financial Reporting*. August, 1--18. <https://doi.org/10.2308/JFR-2021-002>.[Search in Google Scholar](https://scholar.google.com/scholar?q=Sch%C3%BCtt%2C%20Harm%20H.%202023.%20%E2%80%9CWhat%20Can%20Bayesian%20Inference%20Do%20for%20Accounting%20Research%3F%E2%80%9D%20Journal%20of%20Financial%20Reporting%20.%20August%2C%201%E2%80%9318.%20.)


# 

Biondi, Yuri. 2025. "Limits of Empirical Studies in Accounting and Social Sciences: A Constructive Critique from Accounting, Economics and the Law." *Accounting, Economics, and Law: A Convivium* *15* (1): 9--19. <https://doi.org/10.1515/ael-2017-0026>.[Search in Google Scholar](https://scholar.google.com/scholar?q=Biondi%2C%20Yuri.%202025.%20%E2%80%9CLimits%20of%20Empirical%20Studies%20in%20Accounting%20and%20Social%20Sciences%3A%20A%20Constructive%20Critique%20from%20Accounting%2C%20Economics%20and%20the%20Law.%E2%80%9D%20Accounting%2C%20Economics%2C%20and%20Law%3A%20A%20Convivium%2015%20%281%29%3A%209%E2%80%9319.%20.)

# B419：cdist-如何估计反事实的分布特征？

&emsp；

介绍 `cdist` 命令的理论基础和应用。 
```stata
ssc install cdist, replace 
ssc install moremata, replace  // 需要利用该程序包提供的函数
net get cdist.pkg, replace //作者提供的辅助资料
```

`cdist` estimates counterfactual distributions using methods suggested by Chernozhukov et al. (2013). The unconditional (counterfactual) distributions are either obtained by distribution regression using `logit` models or by a linear quantile regression process (using `mm_qr()` from the `moremata` package).

For an alternative implementation of these (and related) methods see package [counterfactual](https://raw.githubusercontent.com/bmelly/Stata/main/) by Blaise Melly (type the following command:
```stata
net from https://raw.githubusercontent.com/bmelly/Stata/main/
```
the package also includes commands `cdeco` and `cdeco_jmp` to perform counterfactual decompositions).

## References

- Chernozhukov, Victor, Iván Fernández-Val, Blaise Melly. 2013. Inference on Counterfactual Distributions. Econometrica 81(6):2205–2268.
- Chernozhukov, Victor, Iván Fernández-Val, Blaise Melly. 2022. Fast algorithms for the quantile regression process. Empirical Economics 62(1):7–33.
- Juhn, Chinhui, Kevin M. Murphy, Brooks Pierce. 1993. Wage Inequality and the Rise in Returns to Skill. Journal of Political Economy 101(3):410-442.
- Portnoy, Stephen, Roger Koenker. 1997. The Gaussian hare and the Laplacian tortoise: computability of squared-error versus absolute-error estimators. Statistical Science 12(4):279-300.


# B427：数据量大时，啥啥都显著
翻译，并适当的调整或添加内容。一定要写出完整的参考资料出处，以免引起版权纠纷。推文的题目可以根据你的理解来拟定，最好能有一定的吸引力。

- Dave Giles, 2019, Blog, [Everything's Significant When You Have Lots of Data](https://davegiles.blogspot.com/2019/10/everythings-significant-when-you-have.html#more)


# B457：介绍Local-DID模型

> [github-lpdid](https://github.com/friosavila/lpdid)

- Markdown 文档生成建议：
  - 复制网页内容 &rarr; 贴入 Typora 编辑器，按 **Ctrl+/** 即可呈现 Markdown 文本。
  - 数学公式：可以用 mathpix 软件扫描获取。

## 简介 LP-DiD

- Dube, A., D. Girardi, O. Jorda, A. M. Taylor, **2023**, A local projections approach to difference-in-differences event studies. [PDF](https://www.frbsf.org/wp-content/uploads/sites/4/wp2023-12.pdf), [Replication](https://github.com/danielegirardi/lpdid), [-cited-](https://scholar.google.com/scholar?cites=2002525239519188943&as_sdt=2005&sciodt=0,5&hl=zh-CN)

Dube, Girardi, Jorda' and Taylor (2023) propose a local projections approach to difference-in-differences event studies - LP-DiD.

This repository contains two STATA do files that implement the LP-DiD estimator in simulated datasets. 

Both examples illustrate the case of binary, staggered and absorbing treatment, when only not yet treated units are used as controls. 

- `LP_DiD_examplefile.do` uses a simulated dataset similar to the Montecarlo simulations presented in Dube, Girardi, Jorda' and Taylor (2023). 

- `lpdid_test.do` applies LP-DiD in a simulated dataset from Borusyak (2021).

# B374：Stata可视化：robbox-好用有强大的的箱型图命令-快速呈现离群值

写一篇推文介绍 `robbox` 命令。帮助文件中提供了大量的例子。

参考文献：
- Jann, B., V. Verardi, C. Vermandele (2019). robbox: Stata module to compute generalized box plots. [-Link-](http://ideas.repec.org/c/boc/bocode/s458620.html)
- Bruffaerts, C., V. Verardi, and C. Vermandele. 2014. A generalized boxplot for skewed and heavy-tailed distributions. Statistics and Probability Letters 95: 110-117.
- Hubert, M., and E. Vandervieren. 2008. An adjusted boxplot for skewed distributions. Computational Statistics and Data Analysis 52: 5186-5201.

# B349：各种IV方法速读：论文推介

参照香樟推文的风格，写一篇推文，介绍下面的论文。

Burgess, S., D. S. Small, S. G. Thompson, **2017**, A review of instrumental variable estimators for mendelian randomization, **Statistical Methods in Medical Research**, 26 (5): 2333-2355. [-Link-](https://doi.org/10.1177/0962280215597579), [-PDF-](https://sci-hub.ren/10.1177/0962280215597579)

- **参考：** 可以参考如下两篇文章的推介文档
  - [Big Bad Banks：多期 DID 经典论文介绍](https://www.lianxh.cn/news/42611191cca93.html)
  - [Chen-2019-Hukou.rar](https://file.lianxh.cn/Lectures/PapersRep/B4a_Chen_2019.rar) &rarr; **Chen_2019_RDD_中文精要.pdf** 


# B655-介绍 I4R 机构和网站

- The Institute for Replication (I4R)：<https://www.i4replication.org/index.html>

提纲：
1. I4R 简介
2. 论文复现的新趋势：I4R 是如何做的 - 提供模板；大规模复现；设置比赛；与期刊合作进行论文复现
3. 在 [publishing](https://www.i4replication.org/publishing.html) 单元介绍了很多资源
4. 工作论文，每年一百多篇复现性质的论文。有助于我们了解如何做复现类论文；如何通过复现提高自己的研究能力
  - https://ideas.repec.org/s/zbw/i4rdps.html



# B422：知乎热议：为什么国内博士毕业的paper普遍比国外博士多？

[为什么我感觉国内博士毕业手里的paper普遍比国外博士多？](https://www.zhihu.com/question/457963341)

参考连享会往期知乎热议专题推文的写法：Stata命令 `lianxh 知乎`

- [知乎热议：读经济学博士（PhD）的感受如何](https://www.lianxh.cn/news/18c08522e5ea3.html)
- [知乎热议：学经济学以后能干什么？](https://www.lianxh.cn/news/b2ff2752d4f6e.html)
- [知乎热议：做学术需要搞清楚计量经济学里全部的数学原理吗？](https://www.lianxh.cn/news/f8b0dbe406fcc.html)
- [知乎热议：对 PhD 一年级新生有什么建议？](https://www.lianxh.cn/news/da7f1c2b5cda5.html)
- [知乎热议：你见过最烂的代码长什么样子？](https://www.lianxh.cn/news/c825de3f13fad.html)
- [知乎热议：发 Top 5 和 Field Top 是什么感觉？](https://www.lianxh.cn/news/f7dd39f31a14a.html)
- [知乎热议：怎样查全一个方向的文献？](https://www.lianxh.cn/news/30dfd5590a695.html)
- [知乎热议：如何搜到专业数据和行业报告](https://www.lianxh.cn/news/bf317876816f1.html)


# B399-mmqreg：quantile regressions via Method of Moments

> Method of Moments Quantile Regression (MMQR) with fixed effects

`mmqreg` estimates quantile regressions using the method of moments as described in Machado and Santos Silva (2019, **JoE**), and expanding the methodology to allow for multiple fixed effects.

In contrast with `xtqreg`, `mmqreg` adds three features to the estimation of this type of models:
1. It allows the estimation of the Location-Scale quantile regressions when there are no fixed effects.
2. Using the command `hdfe` it allows the estimation of LS quantile regression absorbing multiple fix effects
3. It reports the estimation of various quantiles jointly, which facilitates testing of coefficients across quantiles, using **resampling methods** like Bootstrap. (see bootstrap), or based on analytical standard errors.

Also, in contrast with `xtqreg`, standard errors for quantiles, location, and scale effects, can be estimated adjusting for the degrees of freedom.

Furthermore, because this is a GMM estimator, `mmqreg` also provides 3 options for standard errors, the default which is the same as `xtqreg`, robust standard errors, and clustered standard errors.

- 参考资料
- Machado, J.A.F. and Santos Silva, J.M.C. (2019), Quantiles via Moments, Journal of Econometrics, 213(1), pp. 145-173.
- Rios-Avila, Fernando (2020), Extending Quantile regressions via Method of Moments using multiple fixed effects. MIMEO
 
## 安装
```stata
. ssc install hdfe, replace 
. ssc install ftools, replace 

. ssc install mmqreg, replace 
. net get mmqreg.pkg, replace  // 作者提供的范例数据
```

# ok-王凯旋-B376-翻译：异方差稳健性标准误：实操建议

Enrique Pinzon, 2022, Heteroskedasticity robust standard errors: Some practical considerations. [-Link-](https://blog.stata.com/2022/10/06/heteroskedasticity-robust-standard-errors-some-practical-considerations/)

# 金融圈行话暗语大盘点

收集网上的资料，写篇推文。最好能有点趣味，但又不缺少知识性。比如，如下资料可以作为来源的一部分：
- [拒做金融小白，一些“行话”小科普（上）](https://zhuanlan.zhihu.com/p/103692672)
- [金融风控“行话”，一文掌握金融风控专业术语](https://zhuanlan.zhihu.com/p/347740212)
- [金融行业的暗语有哪些？](https://www.zhihu.com/question/65374298)
- [常在金融圈混，不懂点“黑话”怎么行——金融行话盘点](https://zhuanlan.zhihu.com/p/136020595)
- [一审、二审、三审、枪毙](https://www.zhihu.com/question/19635215/answer/135213405)
- [你所知道的行业黑话有哪些？ - 财柒的回答 - 知乎](https://www.zhihu.com/question/19635215/answer/173503200)
- [盘点：科研派“黑话”](https://zhuanlan.zhihu.com/p/64097739)
[有哪些科研圈的通用行话？](https://www.zhihu.com/question/386652986)



# B810-Stata绘图：violinplot-小提琴图

```stata
net describe http://repec.org/bocode/v/violinplot
ssc install violinplot, replace all 

* violinplot requires dstat, moremata, palettes, and colrspace. 
* To install these packages, type:

  ssc install dstat
  ssc install moremata
  ssc install palettes
  ssc install colrspace
```

作者还提供了一个 zip 文件，执行 `ssc install violinplot, replace all ` 命令后会自动下载到当前工作路径下。可以作为推文的素材。

# MCF：Modified Causal Forest 

- Python: `mcf`, [website](https://mcfpy.github.io/mcf/getting_started.html)
- Bodory H, Mascolo F, Lechner M (2024). **Enabling Decision Making with the Modified Causal Forest: Policy Trees for Treatment Assignment**. *Algorithms*. 17(7):318. [Read Paper](https://doi.org/10.3390/a17070318)


# 论文推介：

Di Francesco, R. (2024). Aggregation Trees (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2410.11408) (rep), [PDF](https://arxiv.org/pdf/2410.11408.pdf), [Google](<https://scholar.google.com/scholar?q=Aggregation Trees (Version 1)>).

- R package: `aggTrees`
- website: [Aggregation Trees](https://riccardo-df.github.io/aggTrees/)
  - [教程](https://riccardo-df.github.io/aggTrees/articles/aggTrees-vignette.html)
- `aggTrees` is an R package for *aggregation trees*, a nonparametric approach designed to discover heterogeneous subgroups in a selection-on-observables framework. This method helps researchers assess treatment effect heterogeneity by constructing a hierarchical sequence of optimal groupings, enabling estimation and inference of the group average treatment effects at different levels of granularity.




# 论文推介和复现

Baiardi, A., & Naghi, A. A. (2024). The value added of machine learning to causal inference: evidence from revisited studies. The Econometrics Journal, 27(2), 213–234. [Link](https://doi.org/10.1093/ectj/utae004), [PDF](http://sci-hub.ren/10.1093/ectj/utae004), [Google](<https://scholar.google.com/scholar?q=The value added of machine learning to causal inference: evidence from revisited studies>).

# 论文推介

Bruns, M., & Piffer, M. (2024). Tractable Bayesian estimation of smooth transition vector autoregressive models. The Econometrics Journal, 27(3), 343–361. [Link](https://doi.org/10.1093/ectj/utae009), [PDF](http://sci-hub.ren/10.1093/ectj/utae009), [Google](<https://scholar.google.com/scholar?q=Tractable Bayesian estimation of smooth transition vector autoregressive models>).

# 论文推介

- Arkhangelsky, D., & Imbens, G. (2024). Causal models for longitudinal and panel data: a survey. The Econometrics Journal, 27(3), C1–C61. [Link](https://doi.org/10.1093/ectj/utae014), [PDF](http://sci-hub.ren/10.1093/ectj/utae014), [Google](<https://scholar.google.com/scholar?q=Causal models for longitudinal and panel data: a survey>).

# 论文推介

Fuhr, J., & Papies, D. (2024). Double Machine Learning meets Panel Data -- Promises, Pitfalls, and Potential Solutions (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2409.01266) (rep), [PDF](https://arxiv.org/pdf/2409.01266.pdf), [Google](<https://scholar.google.com/scholar?q=Double Machine Learning meets Panel Data -- Promises, Pitfalls, and Potential Solutions (Version 1)>).

# MCMC

翻译并适当的调整或添加内容。一定要写出完整的参考资料出处，以免引起版权纠纷。推文的题目可以根据你的理解来拟定，最好能有一定的吸引力。

- [Markov Chain Monte Carlo](https://roomno308.github.io/blog/MCMC.html), [.ipynb](https://github.com/roomno308/roomno308.github.io/blob/main/blog/MCMC.md) (可以 Fork 这个仓库后，下载原始 .ipynb 文件，然后进行意译。注意：图片需要上传到连享会图床中。)


## 其它参考资料
- Brian Keng, 2015, Blog. Markov Chain Monte Carlo Methods, Rejection Sampling and the Metropolis-Hastings Algorithm. [Link](https://bjlkeng.io/posts/markov-chain-monte-carlo-mcmc-and-the-metropolis-hastings-algorithm/), [Source](https://bjlkeng.io/posts/markov-chain-monte-carlo-mcmc-and-the-metropolis-hastings-algorithm/index.ipynb)

- [Understanding the basics of Markov Chain Monte Carlo (MCMC) Methods](https://sarowarahmed.medium.com/understanding-the-basics-of-markov-chain-monte-carlo-mcmc-methods-495c257e9ebc)

- [Wikipedia - Markov chain Monte Carlo](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo)
- [Mastering Markov Chain Monte Carlo Methods: A Complete Introduction to MCMC in Machine Learning](https://www.numberanalytics.com/blog/mastering-mcmc-methods)
- [Writing a simple Monte Carlo Markov Chain code](https://carlessanchezalonso.github.io/2020/mcmc/)
- [A Gentle Introduction to Markov Chain Monte Carlo (MCMC)](https://theclevermachine.wordpress.com/2012/11/19/a-gentle-introduction-to-markov-chain-monte-carlo-mcmc/)

# Causal-Copilot

介绍原理，然后使用 [https://causalcopilot.com/](https://causalcopilot.com/) 来做一些测试。 

- github: <https://github.com/Lancelot39/Causal-Copilot>
- [demo-vedio: Causal-Copilot Demo: Tabular Data](https://www.youtube.com/watch?si=3DTT2AlEIcAf-T_E&v=U9-b0ZqqM24&feature=youtu.be)
- [Sample Dataset](https://huggingface.co/Causal-Copilot)


Wang, X., Zhou, K., Wu, W., Singh, H. S., Nan, F., Jin, S., Philip, A., Patnaik, S., Zhu, H., Singh, S., Prashant, P., Shen, Q., & Huang, B. (2025). Causal-Copilot: An Autonomous Causal Analysis Agent (Version 2). arXiv. [Link](https://doi.org/10.48550/arXiv.2504.13263) (rep), [PDF](https://arxiv.org/pdf/2504.13263.pdf), [Google](<https://scholar.google.com/scholar?q=Causal-Copilot: An Autonomous Causal Analysis Agent (Version 2)>). [TeX Source](https://arxiv.org/src/2504.13263)

# ML方法比较

- Lechner, M., & Mareckova, J. (2025). Comprehensive Causal Machine Learning (Version 2). arXiv. [Link](https://doi.org/10.48550/arXiv.2405.10198) (rep), [PDF](https://arxiv.org/pdf/2405.10198.pdf), [Google](<https://scholar.google.com/scholar?q=Comprehensive Causal Machine Learning (Version 2)>).

  - Uncovering causal effects in multiple treatment setting at various levels of granularity provides substantial value to decision makers. Comprehensive machine learning approaches to causal effect estimation allow to use a single causal machine learning approach for estimation and inference of causal mean effects for all levels of granularity. Focusing on selection-on-observables, this paper compares three such approaches, the modified causal forest (MCF), the generalized random forest (GRF), and double machine learning (DML). It also compares the theoretical properties of the approaches and provides proven theoretical guarantees for the mcf. The findings indicate that dml-based methods excel for average treatment effects at the population level (ATE) and group level (GATE) with few groups, when selection into treatment is not too strong. However, for finer causal heterogeneity, explicitly outcome-centred forest-based approaches are superior. The mcf has three additional benefits: (i) It is the most robust estimator in cases when dml-based approaches underperform because of substantial selection into treatment; (ii) it is the best estimator for GATEs when the number of groups gets larger; and (iii), it is the only estimator that is internally consistent, in the sense that low-dimensional causal ATEs and GATEs are obtained as aggregates of finer-grained causal parameters.
  - The practical use of these three CCMLs is supported by the availability of well-maintained software packages: $d m l$ is available as Python and R packages, the $g r f$ is available as an $R$ package, and the $m c f$ is available as a Python package.
    - As examples can serve: Bach, Chernozhukov, Kurz, and Spindler (2022), Bach, Kurz, et al. (2024), and Knaus (2022) for dml; Athey and Wager (2019) for grf; and Bodory et al. (2022) for mcf. The R packages can be downloaded from CRAN. The Python packages are available on PyPI.

# ML中介效应

- Lechner M, Bearth N (2025). **Causal Machine Learning for Moderation Effects**. [Read Paper](https://arxiv.org/abs/2401.08290), Journal of Business & Economic Statistics, acceptted

Bearth, N., & Lechner, M. (2025). Causal Machine Learning for Moderation Effects. arXiv. [Link](https://doi.org/10.48550/arXiv.2401.08290) (rep), [PDF](https://arxiv.org/pdf/2401.08290.pdf), [Google](<https://scholar.google.com/scholar?q=Causal Machine Learning for Moderation Effects (Version 3)>). Journal of Business & Economic Statistics, forthcoming.

# 论文推介：固定效应与混淆变量问题

Burkhardt, J., & Hill, A. E. (2024). Bias Induced by Fixed Effects in the Presence of Collider Variables. [Link](https://doi.org/10.2139/ssrn.5011080), [-PDF-](https://download.ssrn.com/2024/11/5/5011080.pdf?response-content-disposition=inline&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEBIaCXVzLWVhc3QtMSJIMEYCIQC41XE2oH%2ByrDNbVpCvvMNLSzRbBaTTWId0SQoUiQf41wIhAPCC%2BYunh4AY0CMqr0Gu5F6L41tzADPm7hD8tFf%2F6poLKsUFCPv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBBoMMzA4NDc1MzAxMjU3IgwU6Lu7hdJZxMQ8Cr8qmQXMJkzFzwSJcBncqaaQ9y6CdO5s37n3edqDnSt0II3bs8LpgehsH0%2FFvcNyOQHqg2%2FoBBX9ujjH9juiAZGAouljcfJIDhso4uRjFmo7%2B3NLq9US7q4FXoee95SVIXEGFmR351tniVPjudql1Cz3vw7NpBX4J6%2BqBfHomKcJsKVQ8mfU%2FVoB2592zGuCq6GjIl3AfjvyJZpcnAkwuVojCxiv7A2BUgZSJKFBfIFs6uYVyGP5c7mx09WGXboc1xGV0paZo92%2BfV4FVbC%2BsopOTesxafE%2BXR2Tgu2N9TAmzhB%2BDFS4a7j06Qyetf%2FBOhgiw%2FQh6MqRKsyRkU99JVJscHPUub%2BlaCtFimlyhlTIjPOmahoe6Tc%2BH3S0L3e9gbfkN9faxwtUvRycIsKiP3q0haA40pl8NKfaS1EQZ3OTdF09nRWayQRITk5T3NQhvJv2CidCI5RgOhSIJOaDPWzW9S5%2BJHp8SDU9oWNpSZP3E38jGJEjmhcfN1h%2Flm%2FvzhFp5uhpVhZtFuhqdvRveFElzozW61tLDYi7%2BKbraQLKYkoPvZYmVMAP%2BMh%2FSvCHhBA7CUm%2BFIvwFNth8a3S5jR23M1pNIYxX4wWKitm9sDY3SNZHmF6HkOsDqZ9RJLQ6IXxjN0tgLFDYBGOU0QvgppYZSdZArLVWsZoT1Hl30edoGJO0jL5Y6fC6LSNEMw96u%2Bb9OIvEWVE9FAWk%2F3ekQ%2Bi5hNFN1OPds8SRpPlLxA1ineln%2FDYWYGf43tPEFNIljb7qW3G8s0%2BjpBG0lEvhY4WGbIUK90DtY2NEQnIr2XMqVcNua9V29b9Y8vqQDO1esdNuYoIzjbaFR%2Bwkeaz%2FTpgDd2mPIol0cqY5XV5SaOVejjw3bDpsR8RZpvYDzDt3eLCBjqwAd4IoMWsCSSjrg6vWQgmXJ7YLxQcv6ly6fGUnjkBDpDjn0j0lZEbCnsNl7ke7xDQIDp6kcxsLeug8HQL3B1%2F8ddcy0B%2F%2B%2BIXSHyjLEuMqiGym37U0%2BkDR0lcIt3eLWdEknalw6IrEv%2FbNrY%2FVAv%2BmxnWjkPG%2BM5dyKK2d4VgQ1KnRzn3oGOZmg8oHSLxjiO9cxmu%2F7iniBvw%2Fj298LCkPXGgJZlaEuSBpL9vmGuNE5CC&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250623T015922Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAUPUUPRWERVLZGAA6%2F20250623%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=7f7607170a2247ba3a5e16a7a9fb3462b7bfe6af9b71f4b04e0fe00563823cd0&abstractId=5011080), [Google](<https://scholar.google.com/scholar?q=>).
- 作者在 PDF 论文的文末附上了 R codes，可以作为推文的素材。如果你对 Stata 或 Python 比较熟悉，可以借助 AI 把作者提供的 R codes 转换为 Stata 或 Python 代码。

- Abstract: This paper examines the bias introduced in fixed effects estimators when a collider variable influenced by both the explanatory variable and the outcome is absorbed by the fixed effects. We derive an expression for the bias as a function of the within-group and between-group variances of the collider variable and the strength of the induced correlation caused by the collider. The analysis reveals that lower within-group variance or higher between-group variance of the collider amplifies the bias by inducing a stronger correlation between the explanatory variable and the error term. We discuss the implications for empirical research, cautioning against the indiscriminate use of fixed effects and emphasizing the need for careful model specification to mitigate collider bias.
- Keywords: fixed effects, collider variables, endogenous control.




# 控制变量问题

Hünermund, P., & Louw, B. (2023). On the Nuisance of Control Variables in Causal Regression Analysis. Organizational Research Methods, 28(1), 138–151. [Link](https://doi.org/10.1177/10944281231219274), [PDF](https://journals.sagepub.com/doi/epdf/10.1177/10944281231219274), [Google](<https://scholar.google.com/scholar?q=On the Nuisance of Control Variables in Causal Regression Analysis>).


# 翻译+适当修改：混淆变量问题
Frake, J., Hagemann, A., & Uribe, J. (2024). Collider bias in strategy and management research: An illustration using women CEO’s effect on other women’s career outcomes. Strategic Management Journal, 45(7), 1393–1419. Portico. [Link](https://doi.org/10.1002/smj.3588), [PDF](https://sms.onlinelibrary.wiley.com/doi/epdf/10.1002/smj.3588), [Google](<https://scholar.google.com/scholar?q=Collider bias in strategy and management research: An illustration using women CEO’s effect on other women’s career outcomes. Strategic Management Journal, 45(7), 1393–1419>).

# IVDML

- <https://github.com/cyrillsch/IVDML>
  - Note: 你可以 Fork 这个仓库，然后就可以在自己的账号下打开编辑模式，看到原始 Markdown 文档并进行翻译和编辑了。 

## 简介

The IVDML package implements an instrumental variable (IV) estimator for potentially heterogeneous treatment effects in the presence of endogeneity as presented in Scheidegger, Guo and Bühlmann (2025). The estimator is based on double/debiased machine learning (DML) (Chernozhukov et al., 2018) and uses efficient machine learning instruments (MLIV) and kernel smoothing.

We assume that we observe $N$ i.i.d. copies of the model $Y_i=\beta\left(A_i\right) D_i+g\left(X_i\right)+\epsilon_i . Y_i$ is the response variable and $D_i$ is the treatment variable. $X_i$ are the observed covariates and $A_i$ is a univariate continuous covariate with respect to which we want to consider heterogeneity (usually $A_i$ is a component of $X_i$ ). $\epsilon_i$ is an error term that satisfies $E\left[\epsilon_i \mid X_i\right]=0$, but we have endogeneity, meaning that $E\left[\epsilon_i \mid D_i, X_i\right] \neq 0$. To deal with the endogeneity, we assume that we have access to an instrumental variable $Z_i$ that satisfies $E\left[\epsilon_i \mid Z_i, X_i\right]=0$. To goal is to conduct inference on the heterogeneous treatment effect $\beta(a)$ for some specific value $a$ of $A_i$.

We quickly describe the main idea of our estimator. Assume for a moment that the treatment effect $\beta(\cdot)=\beta$ is constant (i.e. does not depend on $A_i$ ). Then, $\beta$ is identified via $\beta=\frac{E\left[\left(Y_i-E\left[Y_i \mid X_i\right]\right)\left(E\left[D_i \mid Z_i, X_i\right]-E\left[D_i \mid X_i\right]\right)\right]}{E\left[\left(D_i-E\left[D_i \mid X_i\right]\right)\left(E\left[D_i \mid Z_i, X_i\right]-E\left[D_i \mid X_i\right]\right)\right]}$. Hence, an estimate $\hat{\beta}$ of $\beta$ can be obtained by estimating the so-called nuisance functions $f\left(Z_i, X_i\right)=E\left[D_i \mid Z_i, X_i\right]$, $\phi\left(X_i\right)=E\left[D_i \mid X_i\right]$ and $l\left(X_i\right)=E\left[Y_i \mid X_i\right]$ using arbitrary user-chosen machine-learning and calculating a sample version of the identification given above. In practice, this is done using a cross-fitting scheme (Chernozhukov et al. 2018).

If we allow for the treatment effect $\beta(\cdot)$ to depend on the univariate continuous quantity $A_i$, and $A_i$ is a component of $X_i$, we can make the identification $\beta(a)=\frac{E\left[\left(Y_i-E\left[Y_i \mid X_i\right]\right)\left(E\left[D_i \mid Z_i, X_i\right]-E\left[D_i \mid X_i\right]\right) \mid A_i=a\right]}{E\left[\left(D_i-E\left[D_i \mid X_i\right]\right)\left(E\left[D_i \mid Z_i, X_i\right]-E\left[D_i \mid X_i\right]\right) \mid A_i=a\right]}$. conditional on $A_i=a$. In the sample version, we then use a kernel function $K(\cdot)$ (for example the Gaussian kernel $K(t)=\exp \left(-t^2 / 2\right) / \sqrt{2 \pi}$ ) to estimate the conditional expectations given $A_i=a$.

For a detailed discussion of the method, we refer to Scheidegger, Guo and Bühlmann (2025). We now demonstrate, how the IVDML package is used in practice.

# RPIV：全新工具变量检验方法

Scheidegger, C., Londschien, M., & Bühlmann, P. (2025). A Residual Prediction Test for the Well-Specification of Linear Instrumental Variable Models (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2506.12771) (rep), [PDF](https://arxiv.org/pdf/2506.12771.pdf), [Google](<https://scholar.google.com/scholar?q=A Residual Prediction Test for the Well-Specification of Linear Instrumental Variable Models (Version 1)>). [R codes](https://github.com/cyrillsch/RPIV_Application)

实操代码：

- [RPIV - R codes](https://github.com/cyrillsch/RPIV)
  - [RPIV Application](https://github.com/cyrillsch/RPIV_Application)

摘要：

- The linear instrumental variable (IV) model is widely applied in observational studies. The corresponding assumptions are critical for valid causal inference, and hence, it is important to have tools to assess the model's well-specification. The classical Sargan-Hansen J-test is limited to the overidentified setting, where the number of instruments is larger than the number of endogenous variables. Here, we propose a novel and simple test for the well-specification of the linear IV model under the assumption that the structural error is mean independent of the instruments. Importantly, assuming mean independence allows the construction of such a test even in the just-identified setting. We use the idea of residual prediction tests: if the residuals from two-stage least squares can be predicted from the instruments better than randomly, this signals misspecification. We construct a test statistic based on sample splitting and a user-chosen machine learning method. We show asymptotic type I error control. Furthermore, by relying on machine learning tools, our test has good power for detecting alternatives from a broad class of scenarios. We also address heteroskedasticity- and cluster-robust inference. The test is implemented in the R package `RPIV` and in the `ivmodels` software package for Python.
- Implementations of our test can be found in the R package `RPIV`, available at <https://github.com/cyrillsch/RPIV>, and as part of the `ivmodels` software package for Python (Londschien and Bühlmann, 2024), available at <https://github.com/mlondschien/ivmodels>.

# https://mml-book.com

- https://mml-book.com
- https://github.com/mml-book/mml-book.github.io
- PDF: https://mml-book.github.io/book/mml-book.pdf

# 使用quarto打造个人主页

- [chizapoth.github.io](https://chizapoth.github.io/)，[github](https://github.com/chizapoth/chizapoth.github.io)
  - 界面清爽，栏目清晰，比较适合学生
  - Blogs 栏目右侧提供了分类标签




- [creating-quarto-websites](https://ucsb-meds.github.io/creating-quarto-websites/)
  - [github](https://github.com/ucsb-meds/creating-quarto-websites/)

![20250612011340](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250612011340.png)


## 风格各异的模版

- 其它使用 quarto 生成的 github 个人主页： <https://github.com/search?q=.github.io+quarto+personal&type=repositories>

- [chizapoth.github.io](https://chizapoth.github.io/)，[github](https://github.com/chizapoth/chizapoth.github.io)
  - 界面清爽，栏目清晰，比较适合学生
  - Blogs 栏目右侧提供了分类标签

- [valegiunchiglia](https://valegiunchiglia.github.io/personal_website/), [github](https://github.com/valegiunchiglia/personal_website)
  - 适合内容少的个人主页，界面简洁
  - 布局：左边大幅图片，右边是文字介绍或文章引文信息
  - 适合在现有下建立子仓库的配置方式
  
- [vbaliga.github.io](https://vbaliga.github.io/), [github](https://github.com/vbaliga/vbaliga.github.io) 
  - 风格简洁，结构简单
  - 不需要配置太多图片，以文字为主，非常朴素

- [mrislambd.github.io/dsandml](https://mrislambd.github.io/dsandml/), [github](https://github.com/mrislambd/mrislambd.github.io)
  - 风格简洁
  - Blog 带有伸缩目录，blog 的呈现效果很好
  - 配置有些复杂


- [drganghe.github.io](https://drganghe.github.io/), [github](https://github.com/drganghe/drganghe.github.io)
  - 适合：内容较多的用户
  - 带有伸缩目录

![20250622001600](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250622001600.png)


- [samanthacsik.github.io](https://samanthacsik.github.io/)，[github](https://github.com/samanthacsik/samanthacsik.github.io)
  - 宽屏，多个栏目，右侧提供了关键词分类

- [kazuyanagimoto.com](https://kazuyanagimoto.com/)，[github](https://github.com/kazuyanagimoto/kazuyanagimoto.github.io)
  - 展示效果很好，但后台文档较为复杂
  - 另外，他用了自己的网址，而不是 github 的网址
  - 不建议初学者使用该模板


# 翻译+Python实操：从正态分布中抽样

> Brian Keng, 2015, Blog, Sampling from a Normal Distribution. [Link](https://bjlkeng.io/posts/sampling-from-a-normal-distribution/), [ipynb](https://bjlkeng.io/posts/sampling-from-a-normal-distribution/index.ipynb)

https://bjlkeng.io/posts/sampling-from-a-normal-distribution/index.ipynb


# 翻译+适当补充：BS公式与Python演示

- [Pricing Derivatives Using Black-Scholes-Merton Model](https://mrislambd.github.io/statandprob/posts/optionprice/)

# 翻译+适当补充：大数定律与中心极限定理

- [Understanding Law of Large Numbers and Central Limit Theorem](https://mrislambd.github.io/statandprob/posts/lln/)

# 多元回归分析-Python实现

- [多元回归分析-Python实现](https://mrislambd.github.io/dsandml/posts/multiplelinreg/)
  - OLS 简介
  - 梯度下降原理和 Python 代码



# 翻译+适当补充：假设检验与p值

- [Hypothesis testing in quant finance](https://reasonabledeviations.com/2021/06/17/hypothesis-testing-quant/)

在此基础上再加上 empirical p-value 的介绍。

# 

  - 我用 ChatGPT 写了一个版本，可以 [自此基础上](https://chatgpt.com/c/684a20e7-19cc-8005-b1ca-8eb20d29afed) 进行修改。

# 翻译+适当补充：如何阅读哲学书籍

- [probability-matching-brief-intro](https://naturalrationality.blogspot.com/2007/11/probability-matching-brief-intro.html)


# 翻译+适当补充-我是如何读书的

- [How I Read Books](https://reasonabledeviations.com/2022/01/24/reading-philosophy/)

- 翻译这篇推文。可以适当意译，以便符合中文读者的阅读习惯。
- 可以借助 AI 工具进行翻译，请务必进行人工校对与适当改写，避免语言过于机械。
- 在开头部分，介绍一下这篇推文的作者和背景。可以参考 [Reasonable Deviations](https://reasonabledeviations.com/) 网站的介绍，也可以搜索作者的个人主页。


# ML-FE 

两篇推文的工作量

- Clarke, P. S., & Polselli, A. (2025). Double machine learning for static panel models with fixed effects. Econometrics Journal. [Link](https://doi.org/10.1093/ectj/utaf011), [PDF](http://sci-hub.ren/10.1093/ectj/utaf011), [Google](<https://scholar.google.com/scholar?q=Double machine learning for static panel models with fixed effects>). [-Appendix-](https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/ectj/PAP/10.1093_ectj_utaf011/2/utaf011_online_appendix.pdf?Expires=1752824167&Signature=WKaiVKLA-00aEZIMO9vx3dhZZgTLCbcqvACdqBy02ZNA6Vqkn-jZ4rl68WMd6y91~Mt9CCPUxQG9RwIdOPMzEbmv4~6u3RNzF8ghXmXTSU8yPREyG4f61PV2SPSBmwbRullB7tjgCDJFz3pKyewAVdjrXcupZSlFjDbGXQWeZzSL87jh9ZYpTK7BfpglF9bHX3uTjxtfTM3mttuqL3ID7W6cWkL238ggg~e7oR1LwCnUaA5x7mtOSwqD3cmDWB4m9jN7Fov2G308VLwHTDPdF-SFqU~~uWWX-8Edf04uDFu67FfTj~-2frvalFBDOF~zysYlVw9rYzHMCoNW7ejvqg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA),  [-Replication-](https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/ectj/PAP/10.1093_ectj_utaf011/2/utaf011_replication_package_clarke_polselli.zip?Expires=1752824167&Signature=b9JFM59g8TeK1BrfE7-iqsJsuLLNwwwNtyYYxekBfIbm-ywodjDsGdHD8gnt8-Rzbk74zzXbo-9m2cb1iG2IUtkPdZwN1P-d4AWk11m6tQm6D9G529RMfLtf6RWqHpckGeiIJbBpeaGm8fYZ8Q-nbseMr0mRZDzBMPGGVx3Hqxrs-Fnki9JTf7RiO3B7thbh2h36r6CKEw67bIZhMDSbLTo10~Y~-6n5pbv-wss9r8X5IdjFGATQSFgqvBT4H2Xadl9JvidxaD9Jc2gnw67aptFhxNIuXn9JGcVKScn-QL7ZwCq8rMNvr6Wg92fTKl5GEpNp8yFPLKiOagFFKApjFQ__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA), 

## 3.2. Model and Assumptions

We extend the partially linear model proposed by Robinson (1988) to panel data by introducing a fixed effect $\alpha_i^*$ to give the partially linear panel regression (PLPR) model

$$
Y_{i t}=D_{i t} \theta_0+g_1\left(\boldsymbol{X}_{i t}\right)+\alpha_i^*+U_{i t}
$$

where $g_1$ is a non-linear nuisance function of $\boldsymbol{X}_{i t}$ and $E\left[U_{i t} \mid D_{i t}, \boldsymbol{X}_{i t}, \alpha_i^*\right]=0$, but $E\left[\alpha_i^* \mid D_{i t}, \boldsymbol{X}_{i t}\right] \neq 0$. The target parameter $\theta_0$ is the average partial effect of continuous $D_{i t}$ such that $d \theta_0=E\left[Y_{i t}(d)-Y_{i t}(0)\right]$, or the average treatment effect (ATE) $E\left[Y_{i t}(1)-Y_{i t}(0)\right]$ for binary treatments.

Following Chernozhukov et al. (2018), we focus on the partialled-out PLPR (PO-PLPR) model

$$
Y_{i t}=V_{i t} \theta_0+l_1\left(\boldsymbol{X}_{i t}\right)+\alpha_i+U_{i t}
$$


$$
V_{i t}=D_{i t}-m_1\left(\boldsymbol{X}_{i t}\right)-\gamma_i
$$

where $l_1$ and $m_1$ are nuisance functions, $\alpha_i$ is a fixed effect, $E\left[U_{i t} \mid V_{i t}, \boldsymbol{X}_{i t}, \alpha_i\right]=0$, and $V_{i t}$ is the residual of a non-linear additive noise treatment model, depending on fixed effect $\gamma_i$, and satisfying $E\left[V_{i t} \mid \boldsymbol{X}_{i t}, \gamma_i\right]=0$. The focus will be on the PO-PLPR rather than the PLPR model because, as shown below, $l_1$ is a conditional expectation over $Y_{i t}$ whereas $g_1$ is a conditional expectation over counterfactual $Y_{i t}(0)$ that must generally be learnt iteratively. Moreover, the orthogonalized score on which DML estimation of $\theta_0$ is based involves $V_{i t}$ whether it is derived under PLPR or PO-PLPR (see Section 5).

## 实现

[-Replication-](https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/ectj/PAP/10.1093_ectj_utaf011/2/utaf011_replication_package_clarke_polselli.zip?Expires=1752824167&Signature=b9JFM59g8TeK1BrfE7-iqsJsuLLNwwwNtyYYxekBfIbm-ywodjDsGdHD8gnt8-Rzbk74zzXbo-9m2cb1iG2IUtkPdZwN1P-d4AWk11m6tQm6D9G529RMfLtf6RWqHpckGeiIJbBpeaGm8fYZ8Q-nbseMr0mRZDzBMPGGVx3Hqxrs-Fnki9JTf7RiO3B7thbh2h36r6CKEw67bIZhMDSbLTo10~Y~-6n5pbv-wss9r8X5IdjFGATQSFgqvBT4H2Xadl9JvidxaD9Jc2gnw67aptFhxNIuXn9JGcVKScn-QL7ZwCq8rMNvr6Wg92fTKl5GEpNp8yFPLKiOagFFKApjFQ__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA)

DML estimation is conducted in r using the XTDML package in the replication package (or accessible in its latest version at <https://github.com/POLSEAN/XTDML> at the time of writing) which is built on DoubleML by Bach et al. ([2024](javascript:;)).

# 论文复现：

- 工作量：视为两篇推文

- Baiardi, A., & Naghi, A. A. (2024). The value added of machine learning to causal inference: evidence from revisited studies. The Econometrics Journal, 27(2), 213–234. [Link](https://doi.org/10.1093/ectj/utae004), [-PDF-](https://watermark.silverchair.com/utae004.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA0wwggNIBgkqhkiG9w0BBwagggM5MIIDNQIBADCCAy4GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMZKPBTHbOj_k_VDOzAgEQgIIC_8BAJuG7iIAG6IKZmU_WIpg0lYkBjmlB4YBi8O109DsmDvyywCN8XNN5syPiTT-ODWuuS7kG3RnVcsaKGpd3F6PWfXGof3y4qRGPEXLmYgzHaXND9L8k0P-hm1BLgzsW-NSFYDoAPtX2BN_pjfcBtSU8ith6y-r4XB9sq9BMrFLxQOdh3UjXA30phX-k3Dw9I638hAKW-wH9MuGpq_pr0QuIpipNcmS4T8OfTSd9iLorzYuVg0clg-ql1OBx0OJMl9UP6U2SGQ87C03zxV0wMG71SOapsf9diSYVGZJ8d1cwCsPo2kIaLwtKahAp9dKOcUzdsmVhk8Xmxzznh1cWxfw6gI6A8msu_6tKSrLm2X6m78r7zhaCv4Zr-SqYLjANSQWOueWTd9ZVw8TRXTWncb8m-9UlWQJig1kZldOBnZM-CzGcQW63eDpD2keFuGzzsobPyY_vC5tVDKygfDd6SjROgKJx3vWjnDjYSfnsz4J31wU3isDMHQ0PIGziJhQ-mQZrC9QrLqgkby6gbW6akjiJAc6SLeovNThKlRtkY-NU1uGzHLKne7lo2YLf_XKZr4SOQQfuPqNNKRKy3PQhr_Jwd8xWvNtT-wcFS8z4J2EPYEjVxRvbfT9qS0uNnhfJ3p-ew6pDRTcHJCh-v5bywaeBgZuSebyaT1Xgs5jNt6XcwdL3-UnL5zaq1wwaI9BUh7P2K452p5IuCBViUzCGR9tQFV-LzFRYjmf0DhBTugnwqPhSqNRKJrC7SUVZGjwPfibhO_Nmo-gmpb4os0nzhnYfw-TkwAAfYYdthIAw54oq3gsK4l_wygJ1JQ2g7mXUJPhkqVulX9mku4ks7tUBgBrJcHH1vbvs3lGWy-in3iHZel1_9WCt3LqyekczyZNElEqe0re5d5PMWX-Ad0127qw_Rctc_QhVAnaojKD2SrmvmGjeEJcH3M_JLFAW66Ch7Id3klo4t1zaODIYmCxVNiYzncSC5coHL5v-L78W9mh66opEENeNMiZmahUMf6Gf), [PDF-wps](https://papers.tinbergen.nl/21001.pdf), [Google](<https://scholar.google.com/scholar?q=The value added of machine learning to causal inference: evidence from revisited studies>).
  - [-Appendix-](https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/ectj/27/2/10.1093_ectj_utae004/1/utae004_online_appendix.pdf?Expires=1752831230&Signature=INLwGecCD8eE256MvLEbADNBC4edPX2XKmfLcsfRp0i~4ix6FTCFwFwhFGBt0euN3jvfqiLKpc19kCTtTpNl0Lw9s86Nx09dN0IJEbGHhGb2~WvyvWpxOgqqhNd15wGB0n~FRpU7orOHGl4gB3grfo4RjwGsqTIolT4OIZiVqKEHqFJfnb8AqErUuBrO9Y5wgf8AjF3ngkdFhGWjFBtgVoV0okqYmkQjVtACqMF9Nb07zjqJod9YsLKWon-NASDLfFcEZyz5BC1OgbWP2zxHv-5F67BEXwwJgdnAALrg774VIcwEjrw0SyNJcfkiZC8RzgQpujSI8w1tY7DRn2WdcA__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA), 提供了文中的公式和模型设定公式等内容。
  - [-Replication-](https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/ectj/27/2/10.1093_ectj_utae004/1/utae004_replication_files.zip?Expires=1752831230&Signature=OorVYyIbynMNU1cIFUk-c-teed1HQWQqF6mSCLCqaZOqTaIFvXONrbRW25tPtetqPAKivd8Pe0paTAijclbTj62lJ72CLqOE0L1oT-Y3MBJzs~qhQDvrhJGHUIPYIfXPHJ8NtL9McpJwlJW31f~AWgEeh7TSim-BQL-o9aj9Uk4BDDCmnncEgWy0fZD7AgmMhPiBGb3hSu0pxYI12qpo-VVPv348iGHR9IK5VDdexYxWIu7uSMpz1O20IakOtzMYeDBhrg5KdDsrQOvMtqu-gg38qymOewNd~Gu8-5qLE4vNGC9swF7g-lxiWcwQa1dIhX2gcQpDyo71GaGz2JtiMQ__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA)，R codes 



# 论文推介：IV 综述

- Borusyak, K., Hull, P., & Jaravel, X. (2024). Design-based identification with formula instruments: a review. The Econometrics Journal, 28(1), 83–108. [Link](https://doi.org/10.1093/ectj/utae003), [PDF](http://sci-hub.ren/10.1093/ectj/utae003), [Google](<https://scholar.google.com/scholar?q=Design-based identification with formula instruments: a review>).

# mvttest

- Andresen, M. E., & Huber, M. (2021). Instrument-based estimation with binarised treatments: issues and tests for the exclusion restriction. The Econometrics Journal, 24(3), 536–558. [Link](https://doi.org/10.1093/ectj/utab002), [PDF](http://sci-hub.ren/10.1093/ectj/utab002), [Google](<https://scholar.google.com/scholar?q=Instrument-based estimation with binarised treatments: issues and tests for the exclusion restriction>). [-Replication-](https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/ectj/24/3/10.1093_ectj_utab002/1/utab002_replication_package.zip?Expires=1752829828&Signature=A6cZ0DV54dSC0U98GVpbobbLj8sz-aLC5ORmak7THBBGYpBks7HBinjIIerICOV0ttSYLCqkPs6Om60~yYwhWQOXX6HpX6gjHK4blLtQS42kXWBOvGtC1tXIsT0QcKMmooIdSzWfrgdVL4aNXl13AiL8W-JRbnQRYxXp3CqouKGdpfyc2umxiU3kLQEN1gGLmBifU-7QA4gzajU6jhZnXUHb~1OVBrvckGOCtXiKo9SohY5ejfjaCoXycRh06CIsTL~xxTn44--jLwGr5NCnPAC8lkQtwTsB5D1LgNSKNLPWMKFRZywFEZe4frC1l9auYUboz~K4juvGfOPy3-B5RA__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA) (包含两篇论文的复现过程) 
- Stata command: `mvtest`
  - [github](https://github.com/martin-andresen/mvttest)

# Man and machine: GPT for second brains

- [Man and machine: GPT for second brains](https://reasonabledeviations.com/2023/02/05/gpt-for-second-brain/)
- 还不确定

# B810：Python明星包：PyPortfolioOpt-投资组合优化分析

写一篇推文，介绍 `PyPortfolioOpt` 包的用法。
- 需要阅读手册和相关资料，补充理论部分
- 建议预先写一个 `.ipynb` 文件，讲义格式，内嵌 Python 代码和结果解读。(Python 环境配置，参见 [Python：安装和环境配置](https://book.lianxh.cn/ds/body/01_1_install-Python-Anocanda.html))。以此为基础在撰写推文，效率会高很多。发布推文时，`.ipynb` 文件可以放在推文的附件中。
- 举例时，对于中国上市公司，可以用 `akshare` 包获取股票数据；对于美股，可以使用 `yfinance` 包获取股票数据。
  - [cookbook](https://github.com/robertmartin8/PyPortfolioOpt/tree/master/cookbook)
  - 里面放置了几个典型的 `.ipynb` 文件，展示了如何使用 `PyPortfolioOpt` 包进行投资组合优化分析。 

## 参考资料

- [PyPortfolioOpt 主页](https://pyportfolioopt.readthedocs.io/en/latest/index.html)
  - [github]()
  - [作者的 blog](https://reasonabledeviations.com/2020/03/19/rebuilding-pyportfolioopt/)

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250612081459.png)

![20250612082027](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250612082027.png)

> Source: [PyPortfolioOpt - Plot](https://pyportfolioopt.readthedocs.io/en/latest/Plotting.html)

![20250612082117](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250612082117.png)

> Source: [PyPortfolioOpt - Plot](https://pyportfolioopt.readthedocs.io/en/latest/Plotting.html)


# 809：Stata可视化：pheatplot-图示系数的显著性

写一篇推文，介绍这个命令的用法。

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250611232839.png)

## 安装

```stata
net install gr0099.pkg, all replace 
```

执行上述命令后，如下两份文件会自动下载到当前工作路径下：

```raw
online_supplement.pdf
pheatplot-examples.do
```

你可以使用 `shellout online_supplement.pdf` 命令打开 `online_supplement.pdf` 文件，也可以执行 `clickout` 命令，以便在屏幕上呈现上述文件。























---

> Update: `2025/6/26 21:50`

# B808：论文精要-sfma-非参数稳健SFA模型

两篇推文的工作量：

- 写一篇中文精要，介绍这个方法的背景、模型设定、估计方法和应用场景。
  - 格式和要求，参见 [论文复现和中文精要类推文写作指南](https://file.lianxh.cn/KC/lianxh_TA_replication_Guide.pdf) (内附往期范例文档).
- 写一个 `.ipynb` 文件，讲义格式，内嵌 Python 代码和结果解读。(Python 环境配置，参见 [Python：安装和环境配置](https://book.lianxh.cn/ds/body/01_1_install-Python-Anocanda.html))


--- - --


Robust non-parametric frontier estimation

> Zheng, P., Worku, N., Bannick, M., Dielemann, J., Weaver, M., Murray, C., & Aravkin, A. (2024). Robust Nonparametric Stochastic Frontier Analysis (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2404.04301) (rep), [PDF](https://arxiv.org/pdf/2404.04301.pdf), [Google](<https://scholar.google.com/scholar?q=Robust Nonparametric Stochastic Frontier Analysis (Version 1)>). [github](https://github.com/ihmeuw-msca/sfma)

- sfma
  - `pip install sfma`
  - `from sfma import SFA`
  - The SFMA package is available for general public use through the Python package `sfma`, available at <https://github.com/ihmeuw-msca/sfma>.

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250610225636.png)

| Model  | Stochastic | Non-parametric | Specified Obs. SE | Outlier-Robust |
| :----- | :--------- | :------------- | :---------------- | :------------- |
| DEA    | x          | ✓              | x                 | x              |
| SFA    | ✓          | x              | x                 | x              |
| StoNED | ✓          | ✓              | x                 | x              |
| SFMA   | ✓          | ✓              | ✓                 | ✓              |

### sfma 的特点

The approach in this paper, dubbed SFMA, addresses three key aspects:

-   1. Nonparametric modeling of the frontier using splines
-   2. Detailed modeling of statistical errors, including reported sampling error, as well as unknown non-sampling error and inefficiencies
-   3. Automated outlier detection and removal.

To provide a robust software tool, we implement a customized optimization algorithm that exploits problem structure and performs a single unified analysis that determines outliers, estimates error statistics, and infers the spline coefficients of the frontier and other covariate multipliers of interest.

The SFMA approach can strongly influence our understanding and interpretation of the results, particularly for complex real datasets like those presented here: GDP vs life expectancy (LE), physician density vs universal health coverage (UHC), and nurse density vs health coverage. For these datasets, SFMA obtains helpful results, while a cross-section of tools available across Stata, R, and Python fall short: StoNED fails to converge, SFA and DEA return results that run counter to conventional wisdom in the field, as described below.

-   1. For LE vs. GDP, DEA shows no change in LE for different levels of GDP, while the SFA 'frontier' stays far below the upper bound of the data, and reports a very steep (almost vertical) increase in life expectancy at low levels of GDP per capita. The SFMA analysis suggests that LE increases gradually with GDP, albeit more at lowest levels of GDP than higher. That result is made possible due to the outlier-removal functionality available to SFMA.

-   2. For health coverage, the DEA analysis suggests that physicians have no effect on UHC above 10 physicians per 10,000 population, a clearly falsifiable conclusion. The SFA and SMFA analyses more plausibly show some benefit of more physicians; SFA gain fails to reach the upper limits of the data.


# B807：编程助手：Cursor - 为经管研究注入 AI 动力的代码编辑器

本文介绍基于人工智能技术的代码编辑器 Cursor，探讨它如何通过智能代码生成、即时代码问答、自动调试等先进功能，显著提升经管专业学生在 Stata、Python 和 R 环境下开展数据分析与实证研究的编程效率。

**应用场景展示**：

- 场景一：在网络上找到了一段复杂的 Stata 回归代码，学生难以快速理解。Cursor 可通过自然语言请求即时给出清晰解释，帮助学生准确理解代码逻辑。

- 场景二：使用 Cursor 快速生成 Python 数据清洗和可视化代码。只需用简单的自然语言描述需求，即可获得一整套高效、可直接运行的分析脚本。

参考资料：

- 官方网站：[Cursor](https://cursor.sh/)
- [Cursor AI 使用指南与实践示例](https://www.datacamp.com/tutorial/cursor-ai-code-editor)

---

# B806：翻译+扩充：Stata：pretrends-更严谨的平行趋势检验

请参考 GitHub 项目：[stata-pretrends](https://github.com/mcaceresb/stata-pretrends)，参阅相关论文，写一篇推文，介绍 `pretrends` 命令的理论基础和使用方法。

- 理论基础：[Roth (2022)](https://jonathandroth.github.io/assets/files/roth_pretrends_testing.pdf)
- 介绍应用时，务必W花点篇幅，介绍 [He and Wang (2017)](https://www.aeaweb.org/articles?id=10.1257/app.20160079) 一文的故事背景和数据情况。 

The `pretrends` package provides tools for power calculations for pre-trends tests, and visualization of possible violations of parallel trends. Calculations are based on [Roth (2022)](https://jonathandroth.github.io/assets/files/roth_pretrends_testing.pdf). This is the Stata version of the [R package of the same name](https://github.com/jonathandroth/pretrends). (Please cite the paper if you enjoy the package!)

温馨提示：

- 可以借助 AI 工具进行翻译，但务必手动运行全部代码，确保结果准确。
- 完成翻译后，请务必进行人工校对与适当改写，避免语言过于机械。
- 参考文献可以用 `getiref` 命令自动获取。 

---

# B805：Github 项目推介：MinerU

**项目简介**：MinerU 是一款开源工具，可精准地将 PDF 格式的学术文献（尤其是英文期刊论文）转换为 Markdown 或 JSON 格式，识别精确度高，特别适合处理论文中的版式、表格、公式和图片等复杂元素，大幅提升研究者的文献数字化管理效率。

**应用演示**：

以经济学顶级期刊 PDF 论文为例，使用 MinerU 的简单命令行工具演示转换过程，直观展示其在提取表格、公式方面的卓越表现。

- GitHub 项目链接：[MinerU](https://github.com/opendatalab/MinerU)

---

# B804：双重机器学习速通指南

本文系统地讲解如何在 Stata 中实现双重机器学习（Double Machine Learning）。

**撰写要点**：

1. 明确演示在 Stata 中配置 Python 环境的完整步骤，解决用户常见的难点。
2. 提供可完全复现的经济学实证论文示例，包含使用 `ddml` 命令从基础回归到内生性处理、稳健性测试、机制分析及异质性检验等全套流程。

参考资料：[双重机器学习官方网站](https://statalasso.github.io/)


> `2025/6/11 19:49`

# B803：EconML：因果机器学习的实现流程

本文介绍用于因果推断的 Python 库 EconML。相比于传统在 Stata 环境中实现的 DML 方法，EconML 具备更高的灵活性和扩展性，成为双重机器学习研究的理想工具。

**突出展示的进阶应用**：

- 元学习器（Meta-Learners）的应用
- 因果森林（Causal Forests）方法
- 深度工具变量（Deep IV）技术

参考链接：

- [EconML 官方文档](https://econml.azurewebsites.net/index.html)
- GitHub 项目：[EconML](https://github.com/microsoft/EconML)

# B802：Python 仓库介绍：skfolio

- https://github.com/skfolio/skfolio
- [website](https://skfolio.org/)

## 1. skfolio 的定位与主要功能

`skfolio` 是一个专为 **投资组合优化**（portfolio optimization）、**绩效评估** 和 **风险分析**设计的 Python 包。它灵感来源于 `scikit-learn` 的 API 规范，兼容 `pandas` 和 `numpy`，支持与机器学习管道集成。其主要目标是让用户能够方便地进行多资产投资组合建模、优化、回测和分析。

主要特点包括：

* **投资组合建模**：提供多种投资组合模型（如均值-方差、Black-Litterman、风险平价等）和优化器。
* **集成机器学习管道**：支持与 scikit-learn 流水线（pipeline）无缝集成，可结合特征工程、时间序列预测等机器学习流程。
* **丰富的风险/收益指标**：内置多种投资组合绩效评估和风险度量工具（如夏普比率、索提诺比率、最大回撤等）。
* **自动化多资产回测**：支持资产收益率输入，自动执行优化、权重分配及绩效分析。

## 2. 安装方法

```bash
pip install skfolio
```

## 3. 基本使用流程

### 3.1 数据准备

通常需要一个多资产的收益率时间序列（可以是 DataFrame 格式，每列为一个资产）。

```python
import pandas as pd
returns = pd.read_csv('your_returns.csv', index_col=0, parse_dates=True)
# 每一列为不同资产的日收益率
```

### 3.2 投资组合模型与优化

以经典均值-方差（Mean-Variance）模型为例：

```python
from skfolio import MeanVariance, PortfolioOptimizer

# 创建一个均值-方差模型
model = MeanVariance()

# 创建优化器（最大化夏普比率）
optimizer = PortfolioOptimizer(model=model, objective="sharpe")

# 拟合优化器并获得最优投资组合
optimizer.fit(returns)
optimal_portfolio = optimizer.get_optimal_portfolio()
print(optimal_portfolio.weights)  # 输出各资产权重
```

### 3.3 绩效评估与风险指标

```python
from skfolio.metrics import sharpe_ratio, max_drawdown

# 直接调用绩效指标
sr = sharpe_ratio(optimal_portfolio)
md = max_drawdown(optimal_portfolio)
print(f"Sharpe Ratio: {sr}, Max Drawdown: {md}")
```

### 3.4 与机器学习管道集成

`skfolio` 支持与 scikit-learn 兼容的流水线，比如结合特征选择或回归预测模型：

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from skfolio import MeanVariance, PortfolioOptimizer

pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('optimizer', PortfolioOptimizer(model=MeanVariance(), objective="sharpe"))
])

pipe.fit(returns)
```

## 4. 支持的主要模型与功能

* 均值-方差模型（Mean-Variance, Markowitz）
* Black-Litterman 模型
* 风险平价（Risk Parity）
* 等权重（Equal Weight）
* 多种目标函数（最大化夏普比率、最小化方差、目标收益、目标风险等）
* 约束条件设置（如最大/最小持仓，行业暴露约束等）
* 时间序列回测与可视化

## 5. 与同类包的对比

| 包名           | 优势                                             | 劣势                                    |
| -------------- | ------------------------------------------------ | --------------------------------------- |
| skfolio        | sklearn 风格，API 友好，机器学习集成好，约束丰富 | 功能较新，社区资料有限                  |
| PyPortfolioOpt | 经典投资组合优化全，文档多                       | 主要偏向 Markowitz 和 Black-Litterman   |
| bt             | 强大的回测系统，支持复杂策略设计                 | 学习曲线略陡峭，投资组合建模灵活性一般  |
| riskfolio-lib  | 风险分散策略丰富，支持多种风险模型               | 机器学习集成弱，API 不如 skfolio 现代化 |

## 6. 官方资料与文档

* [skfolio 官方文档](https://skfolio.org/)
* [skfolio GitHub](https://github.com/skfolio/skfolio)

## 7. 参考文献

如需系统阅读投资组合优化和相关理论，推荐以下经典文献：

* Markowitz, H. (1952). Portfolio Selection. The Journal of Finance, 7(1), 77–91. [Link](https://doi.org/10.2307/2975974), [PDF](http://sci-hub.ren/10.2307/2975974), [Google](https://scholar.google.com/scholar?q=Portfolio+Selection+Markowitz)





# B801：新书推介：大语言模型精要

- Jay Alammar and Maarten Grootendorst, 2024, Hands-On Large Language Models. O'Reilly. [-Link-](https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/), [website](https://www.llm-book.com/)
  - [github](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models), [github-中文](https://github.com/bbruceyuan/Hands-On-Large-Language-Models-CN) 
  - [中文推介](https://blog.csdn.net/2301_81888214/article/details/145735234)


# B800：翻译：LLM-Agents简介

- Maarten Grootendorst, 2024. A Visual Guide to LLM Agents: Exploring the main components of Single- and Multi-Agents. [-Link-](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-llm-agents), [中文](https://mp.weixin.qq.com/s/QFJyS0TUCv-TT39isRLu3w)


# B799：翻译：词向量的原理

[Jay Alammar](https://jalammar.github.io/), The Illustrated Word2vec, [-Link-](<https://jalammar.github.io/illustrated-word2vec/>), [中文版](https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&mid=2651669277&idx=2&sn=bc8f0590f9e340c1f1359982726c5a30&chksm=bd4c648e8a3bed9817f30c5a512e79fe0cc6fbc58544f97c857c30b120e76508fef37cae49bc&scene=0&xtrack=1#rd)

# B798：bnlearn-基于贝叶斯的因果关系自动发掘工具

`bnlearn` is Python package for causal discovery by learning the graphical structure of Bayesian networks, parameter learning, inference, and sampling methods. Because probabilistic graphical models can be difficult to use, `Bnlearn` contains the most-wanted pipelines. Navigate to [API documentations](https://erdogant.github.io/bnlearn/) for more detailed information.

- [website](https://erdogant.github.io/bnlearn/pages/html/index.html)
- [github](https://github.com/erdogant/bnlearn)

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250530003653.png)

### Key Pipelines

| Feature | Description |
| --- |  --- |
| [**Causal Discovery / Structure Learning**](https://erdogant.github.io/bnlearn/pages/html/Structure%20learning.html) | Learn the model structure from data or with expert knowledge. |
| --- |  --- |
| [**Parameter Learning**](https://erdogant.github.io/bnlearn/pages/html/Parameter%20learning.html) | Estimate model parameters (e.g., conditional probability distributions) from observed data. |
| [**Causal Inference**](https://pgmpy.org/examples/Causal%20Inference.html) | Compute interventional and counterfactual distributions using do-calculus. |
| [**Generate Synthetic Data**](https://erdogant.github.io/bnlearn/pages/html/Sampling.html) | Generate synthetic data. |
| [**Discretize Data**](https://erdogant.github.io/bnlearn/pages/html/Discretizing.html) | Discretize continuous datasets. |


### Resources and Links

-   **Example Notebooks:** [Examples](https://erdogant.github.io/bnlearn/pages/html/Documentation.html#google-colab-notebooks)
-   **Blog Posts:** [Medium](https://erdogant.medium.com/)
-   **Documentation:** [Website](https://erdogant.github.io/bnlearn)

# B797：Python包：distfit-分布拟合

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250530002953.png)

写一篇推文，介绍 Python 中的 distfit 包，并在推文中插入一些简单的例子，来展示这个包的一些独特的功能。

- [distfit 主页](https://erdogant.github.io/distfit/pages/html/index.html)
  - [github](https://github.com/erdogant/distfit)

### Key Features

| Feature | Description |
| --- |  --- |
| [**Parametric Fitting**](https://erdogant.github.io/distfit/pages/html/Parametric.html) | Fit distributions on empirical data X. |
| --- |  --- |
| [**Non-Parametric Fitting**](https://erdogant.github.io/distfit/pages/html/Quantile.html) | Fit distributions on empirical data X using non-parametric approaches (quantile, percentiles). |
| [**Discrete Fitting**](https://erdogant.github.io/distfit/pages/html/Discrete.html) | Fit distributions on empirical data X using binomial distribution. |
| [**predict**](https://erdogant.github.io/distfit/pages/html/Functions.html#module-distfit.distfit.distfit.predict) | Compute probabilities for response variables y. |
| [**Generate Synthetic Data**](https://erdogant.github.io/distfit/pages/html/Generate.html) | Generate synthetic data. |
| [**Plots**](https://erdogant.github.io/distfit/pages/html/Plots.html) | Varoius plotting functionalities. |

### Resources and Links

-   **Example Notebooks:** [Examples](https://erdogant.github.io/distfit/pages/html/Documentation.html)
-   **Blog Posts:** [Medium](https://erdogant.github.io/distfit/pages/html/Documentation.html#medium-blog)
-   **Documentation:** [Website](https://erdogant.github.io/distfit)



# B796：marker：快速将PDF表格转换为Markdown或JSON数据

- [github](https://github.com/vikParuchuri/marker)

Marker converts documents to markdown, JSON, and HTML quickly and accurately.

-   Converts PDF, image, PPTX, DOCX, XLSX, HTML, EPUB files in all languages
-   Does structured extraction, given a JSON schema (beta)
-   Formats tables, forms, equations, inline math, links, references, and code blocks
-   Extracts and saves images
-   Removes headers/footers/other artifacts
-   Extensible with your own formatting and logic
-   Optionally boost accuracy with LLMs
-   Works on GPU, CPU, or MPS

## Performance


![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250530101756.png)

Marker benchmarks favorably compared to cloud services like Llamaparse and Mathpix, as well as other open source tools.

The above results are running single PDF pages serially. Marker is significantly faster when running in batch mode, with a projected throughput of 122 pages/second on an H100 (.18 seconds per page across 22 processes).

As you can see, the use\_llm mode offers higher accuracy than marker or gemini alone.

## Examples


| PDF | File type | Markdown | JSON |
| --- |  --- |  --- |  --- |
| [Think Python](https://greenteapress.com/thinkpython/thinkpython.pdf) | Textbook | [View](https://github.com/VikParuchuri/marker/blob/master/data/examples/markdown/thinkpython/thinkpython.md) | [View](https://github.com/VikParuchuri/marker/blob/master/data/examples/json/thinkpython.json) |
| [Switch Transformers](https://arxiv.org/pdf/2101.03961.pdf) | arXiv paper | [View](https://github.com/VikParuchuri/marker/blob/master/data/examples/markdown/switch_transformers/switch_trans.md) | [View](https://github.com/VikParuchuri/marker/blob/master/data/examples/json/switch_trans.json) |
| [Multi-column CNN](https://arxiv.org/pdf/1804.07821.pdf) | arXiv paper | [View](https://github.com/VikParuchuri/marker/blob/master/data/examples/markdown/multicolcnn/multicolcnn.md) | [View](https://github.com/VikParuchuri/marker/blob/master/data/examples/json/multicolcnn.json) |

## Installation

You'll need python 3.10+ and PyTorch. You may need to install the CPU version of torch first if you're not using a Mac or a GPU machine. See [here](https://pytorch.org/get-started/locally/) for more details.

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250530173405.png)

复制上图生成的代码，通过命令行运行：

- 按快捷键 Win+R，输入 `cmd`，打开命令行窗口
- 贴入 `pip3 install torch torchvision torchaudio` 命令。

然后，使用如下命令安装 `marker` 包:

```
pip install marker-pdf
```

If you want to use marker on documents other than PDFs, you will need to install additional dependencies with:

```
pip install marker-pdf[full]
```


# B795：推文+小视频：英文PDF文档转中文

- 任务 1：写一篇推文介绍如何使用 <https://pdf2zh.com/> 这个在线网站，快速将英文 PDF 翻译为中文版本。
  - 关键：自己亲自操作，将遇到的各种注意事项写在推文中。

- 任务 2：以推文为基础，录制一个 2-3mins 的小视频，随后通过连享会的视频号发布。

- 网站：https://pdf2zh.com/  
  - [github](https://github.com/Byaidu/PDFMathTranslate)
  


# B794：公开API资源汇总

Try Public APIs for free

写一篇推文，介绍各类公开 API 资源

- https://github.com/public-apis/public-apis




# B793：Stata：biastest-不同模型间系数差异检验

Guliyev, H. (2025). biastest: Testing parameter equality across different models in Stata (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2502.15049) (rep), [PDF](https://arxiv.org/pdf/2502.15049.pdf), [Google](<https://scholar.google.com/scholar?q=biastest: Testing parameter equality across different models in Stata (Version 1)>).

安装：

```stata
ssc install biastest

help biastest
```

可以根据帮助文件写推文，也可以到作者的主页，github，以及 google 上搜索相关资料进行补充。



# B792：Python 包介绍：akshare

- akshare (python 包)：<https://akshare.akfamily.xyz/>
- aktools (通用): <https://aktools.akfamily.xyz/>

要提供可以实操的 Python 代码。所有代码必须在 Python 中测试通过。

最好建立一个 .ipynb 文件，里面包含如下内容：
# akshare 简介
`akshare` 是一个开源的 Python 库，旨在为用户提供便捷的金融数据获取和分析功能。它支持多种数据源，包括股票、期货、外汇、宏观经济等，用户可以通过简单的 API 调用获取实时或历史数据。
# akshare 的主要功能
- **数据获取**：支持股票、期货、外汇、宏观经济等多种金融数据的获取。
- **数据分析**：提供多种数据处理和分析工具，包括技术指标计算、数据可视化等。
- **多数据源支持**：可以从多个数据源获取数据，包括新浪财经、网易财经、东方财富等。
- **易用性**：提供简单易用的 API 接口，用户无需复杂的配置即可使用。
- **社区支持**：拥有活跃的社区和文档，用户可以方便地获取帮助和分享经验。


# B791：数据分析常用提示词梳理

参考：

- [AI Prompts for Data Analysis](https://www.analyticshacker.com/analytics-resources/ai-prompts-for-data-analysis)
- [33 AI Prompts for Data Analysis
Examples for ChatGPT, Claude, Gemini and other LLMs](https://promptdrive.ai/ai-prompts-data-analysis/)
- YouTube 视频：[Prompt Engineering for Data Analysis (Python, Pandas, Chat GPT)](https://youtu.be/uuprB1LpT8Y?si=r0hdXwB7dUxQEiCH)



# B790：如何组织AI提示词工作流程

How To Organize AI Prompt Workflows

参考如下推文的结构，写一篇针对经管专业学生的推文。你可以记住ai把如下推文的链接或者是内容梳理出来发给ai，让他仿照这个写一个针对经管学生的。如果不太清楚提示词怎么写，可以先列个提纲，然后找我来讨论。

- [How To Organize AI Prompt Workflows](https://promptdrive.ai/how-to-organize-ai-prompt-workflows/)

# B789：编程助手：Windsurf Plugin

备选题目： Coedium 还是 Copilot？编程助手如何选？

自行查阅资料，写一篇推文介绍这两个编程助手的区别和优缺点。

以下是我收集到的一些资料：

- Karl Esi, 2024, Blog, [Why Use Codeium over GitHub Copilot](https://dev.to/thekarlesi/why-use-codeium-over-github-copilot-491e)
- [Windsurf Plugin (formerly Codeium)](https://marketplace.visualstudio.com/items?itemName=Codeium.codeium)
  - 里面的动图可以直接拿来用

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250515170341.png)

![Windsurf Plugin (formerly Codeium)](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250515164601.png)

> 设定密匙 token

1. In VSCode, open the Command Palette (**Ctrl/Cmd + Shift + P**), type Windsurf: `Provide Authentication Token`, and hit Enter.
2. Paste your token from step 1 and hit **Enter**.

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250515165916.png)


> Once the usage limit is reached, Cascade can continue to be used with the Cascade Base model. To continue using premium models, upgrade your plan.

# B788：Python：期权定价公式及实现

以这篇 Blog 为基础，写一篇推文介绍期权定价公式及其 Python 实现。

- [Binomial Trees in the Finance Toolkit](https://www.jeroenbouma.com/articles/binomial-trees)


# B787：ylearn：轻松实现因果分析的Python包

写一篇推文，介绍 `ylearn` 包的主要功能和使用方法。主要基于 [ylearn 简介](https://github.com/DataCanvasIO/YLearn/blob/main/README_zh_CN.md)

参考资料：

- 中文：<https://ylearn.readthedocs.io/zh-cn/latest/>
- Pipy: <https://pypi.org/project/ylearn/>

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250611104159.png)

![](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250611104354.png)

先介绍 `ylearn` 包的主要功能和特点，然后给出一个简单的使用示例，最后可以提及一些应用场景或优势。

推文中展示的 Python 实例，务必在 Jupyter Notebook 中运行通过，确保代码可执行。

# B786：HyperTS：端到端的时间序列分析工具

Xiaojing Zhang，Haifeng Wu，Jian Yang. HyperTS: A Full-Pipeline Automated Time Series Analysis Toolkit. https://github.com/DataCanvasIO/HyperTS. 2022. Version 0.2.x.

基于 <https://github.com/DataCanvasIO/HyperTS/blob/main/README_zh_CN.md> 写一篇推文介绍 `HyperTS` 包的主要功能和使用方法。[Examples](https://github.com/DataCanvasIO/HyperTS/tree/main/examples/zh_CN) 中提供了很多 .ipynb 文件，可以直接在 Jupyter Notebook 中运行。

# B785：FinanceDatabase：Github公开数据仓库简介

写一篇推文介绍这个仓库：[Github - JerBouma/FinanceDatabase](https://github.com/JerBouma/FinanceDatabase)，[项目主页](https://www.jeroenbouma.com/projects/financedatabase)

- 可以借助 AI
- 写作过程中务必亲自在 Python 中操作一下，至少测试其中 3-5 个接口的数据获取。然后选取 1-2 个有特色的，放在一个 Section 中加以介绍 (附上完整的 Python 代码，可以借助 AI 生成，但一定要自己亲测能跑通)
  - [项目主页](https://www.jeroenbouma.com/projects/financedatabase) 的 **Projects** 和 **Usage** 部分都可以参考

## 简介

**This database tries to solve that**. It features 300.000+ symbols containing Equities, ETFs, Funds, Indices, Currencies, Cryptocurrencies and Money Markets. It therefore allows you to obtain a broad overview of sectors, industries, types of investments and much more.

The aim of this database is explicitly *not* to provide up-to-date fundamentals or stock data as those can be obtained with ease (with the help of this database) by using the [Finance Toolkit](https://github.com/JerBouma/FinanceToolkit). Instead, it gives insights into the products that exist in each country, industry and sector and gives the most essential information about each product. With this information, you can analyse specific areas of the financial world and/or find a product that is hard to find. See for examples on how you can combine this database, and the earlier mentioned packages the section [Usage](https://github.com/JerBouma/FinanceDatabase#usage). 

Some key statistics of the database:

| Product          | Quantity | Sectors | Industries | Countries |
|------------------|----------|---------|------------|-----------|
| Equities         | 158,429  | 12      | 63         | 111       |
| ETFs             | 36,786   | 295     | 22         | 111       |
| Funds            | 57,881   | 1,541   | 52         | 111       |

| Product          | Quantity | Category          |
|------------------|----------|-------------------|
| Currencies       | 2,556    | 175 Currencies    |
| Cryptocurrencies | 3,367    | 352 Cryptocurrencies |
| Indices          | 91,183   | 64 Exchanges      |
| Money Markets    | 1,367    | 3 Exchanges       |

# B784：论文推介：贝叶斯SFA

Wei, Z., Choy, S. T. B., Wang, T., & Zhu, X. (2025). Bayesian stochastic frontier models under the skew-normal half-normal settings. Journal of Productivity Analysis. [Link](https://doi.org/10.1007/s11123-025-00757-3), [PDF](https://link.springer.com/content/pdf/10.1007/s11123-025-00757-3.pdf), [Google](<https://scholar.google.com/scholar?q=Bayesian stochastic frontier models under the skew-normal half-normal settings>). [github](https://github.com/ZWeiSTAT/BayesianSNSFM.git) (R codes, Data, Jupyter Notebook)

- 介绍论文的核心思想、适用场景和假设条件
- 模型设定和估计方法简介
- R 语言实现 [github](https://github.com/ZWeiSTAT/BayesianSNSFM.git) (R codes, Data, Jupyter Notebook) 

> Note: 我用 ChatGPT 生成了一个大概的提纲，你可以在此基础上进行修改和完善。[点击查看 B784-BayesSFA.md](https://github.com/arlionn/lianxhta/blob/main/sample/B784-BayesSFA.md)

----

> `2025/5/12 15:07`

# B783：开心Python：手绘风格的数据可视化

**任务：** 根据如下资料写一篇推文介绍如何使用 Python 来实现手绘风格的数据可视化。

> 你可以在 [ChatGPT 对话](https://chatgpt.com/share/6820d613-a638-8005-bc11-1ac6aae9b5f5) 基础上继续追问，形成推文。但一定要在 Python 中使用 jupyter notebook 来实现，自己生成图形插入文中。这样才能确保我们提供的代码都是可以执行的。


--- - --


## 简介

适合于商业展示，比较轻松的小组展示等。

## 使用 matplotlib 扩展包

![20250512003110](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250512003110.png)

![20250512001726](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250512001726.png)

- [matplotlib - 手绘风格的图形](https://matplotlib.org/stable/gallery/showcase/xkcd.html#sphx-glr-gallery-showcase-xkcd-py)
- [How To Make Hand-Drawn Style Plots In Python](https://medium.com/geekculture/how-to-make-hand-drawn-style-plots-in-python-709693f6877b)

- [matplotlib.pyplot.xkcd](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.xkcd.html)

```python
with plt.xkcd():
    # This figure will be in XKCD-style
    fig1 = plt.figure()
    # ...

# This figure will be in regular style
fig2 = plt.figure()
```

<br>
<br>

<br>
<br>
<br>
<br>
## 使用 py-roughviz/pygal 扩展包

![20250512001837](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250512001837.png)

- [上图对应的推文](https://medium.com/@nick-tan/want-to-get-away-from-the-standard-looks-of-the-charts-or-graphs-generated-by-matplotlib-and-cbdd7baaeae)

Want to get away from the "standard" looks of the charts or graphs generated by Matplotlib and Seaborn?

Here are three alternative visualization packages that offer **fun**, **playful**, and **unconventional** visualization styles:
- [py-roughviz](https://github.com/charlesdong1991/py-roughviz): Python 封装的 RoughViz.js，支持手绘风格的可视化。
- [pygal](http://www.pygal.org/en/stable/): 简洁优雅的 Python 图表库，支持 SVG 输出和多种图表类型。
- [cutecharts](https://github.com/cutecharts/cutecharts.py): 轻量级、手绘风格的 Python 可视化库，适合快速生成有趣的图表。

## 使用 cutecharts 扩展包

- [github](https://github.com/cutecharts/cutecharts.py)

![20250512002352](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250512002352.png)

- [Make the cutest chart in Python -visualize your data with hand-drawn charts](https://towardsdatascience.com/make-the-cutest-chart-in-python-visualize-your-data-with-hand-drawn-charts-f21157f76b4b/)


# B782：UCINET：社会网络分析利器介绍
- [UCINET](https://sites.google.com/site/ucinetsoftware/home)
  - [UCINET 6 for Windows](https://sites.google.com/site/ucinetsoftware/home/ucinet-6-for-windows)
  - [NetDraw](https://sites.google.com/site/netdrawsoftware/)
  - [UCINET 6 for Windows Manual](https://sites.google.com/site/ucinetsoftware/home/ucinet-6-for-windows/manual)
  - [NetDraw Manual](https://sites.google.com/site/netdrawsoftware/manual)
  - [UCINET 6 for Windows Tutorial](https://sites.google.com/site/ucinetsoftware/home/ucinet-6-for-windows/tutorial)

# B781：PNET：社会网络分析利器介绍

- [PNET 官网](https://www.melnet.org.au/pnet/)
  - [PNet User Manual](https://www.melnet.org.au/s/PNetManual.pdf) 
  - [MPNet User Manual](https://www.melnet.org.au/s/MPNetManual.pdf)
  - [MPNet Tutorial](https://static1.squarespace.com/static/57a1436215d5dbbcd2031828/t/629422ef5c17c102ff150f96/1653875458648/MPNet+tutorial.pdf)


# B780：Python：金融数据库-FinanceDatabase

写一篇推文介绍这个仓库和 Python 包。并在推文中插入几个简单的例子，来展示这个包的一些独特的功能。

主要参考文档是其 [website](https://www.jeroenbouma.com/projects/financedatabase)。

- github: https://github.com/JerBouma/FinanceDatabase
- Website: https://www.jeroenbouma.com/projects/financedatabase
**This database tries to solve that**. It features 300.000+ symbols containing Equities, ETFs, Funds, Indices, Currencies, Cryptocurrencies and Money Markets. It therefore allows you to obtain a broad overview of sectors, industries, types of investments and much more.

The aim of this database is explicitly *not* to provide up-to-date fundamentals or stock data as those can be obtained with ease (with the help of this database) by using the [Finance Toolkit 🛠️](https://github.com/JerBouma/FinanceToolkit). Instead, it gives insights into the products that exist in each country, industry and sector and gives the most essential information about each product. With this information, you can analyse specific areas of the financial world and/or find a product that is hard to find. See for examples on how you can combine this database, and the earlier mentioned packages the section [Usage](https://github.com/JerBouma/FinanceDatabase#usage).

# B779：Python 扩展包：Freqtrade 介绍

- Freqtrade is a free and open source crypto trading bot written in Python. It is designed to support all major exchanges and be controlled via Telegram or webUI. It contains backtesting, plotting and money management tools as well as strategy optimization by machine learning.

# B778：金融中的机器学习仓库

写一篇推文介绍这个仓库，并列举一些有趣的项目。最好能找到 3-5 篇使用该仓库扩展包的论文，列出完整的引文信息，以便读者了解该扩展包在学术文献中的用途。 

- [financial-machine-learning](https://github.com/firmai/financial-machine-learning)
  - 列示了上百个金融分析的仓库和项目
  - Fork 这个仓库，然后把 Wiki 中的仓库列表整理成一篇推文


----

> `2025/4/6 9:13`

# B777：推介：经济学家的深度学习

介绍这篇论文的核心观点，以及文中提及的主要深度学习方法。

- Melissa Dell. "Deep Learning for Economists." *Journal of Economic Literature*, forthcoming [Paper](https://econdl.github.io/redirects/publications/econdl)

**重点介绍作者提供的这个网站**：<https://econdl.github.io/>
- [Packages](https://econdl.github.io/packages.html), [Datasets](https://econdl.github.io/datasets.html)


# B776：AI助力：基于大语言模型的研究假设论证

- Ludwig, J., & Mullainathan, S. (2024). Machine Learning as a Tool for Hypothesis Generation. The Quarterly Journal of Economics, 139(2), 751–827. [Link](https://doi.org/10.1093/qje/qjad055) (rep), [PDF](https://bpb-us-w2.wpmucdn.com/voices.uchicago.edu/dist/3/1161/files/2024/02/QJE-machine-learning-for-hypothesis-generation-202461-8f8c19422434d44d.pdf), [Google](<https://scholar.google.com/scholar?q=Machine Learning as a Tool for Hypothesis Generation>).
- Batista, Rafael and Ross, James, Words that Work: Using Language to Generate Hypotheses (July 01, 2024). Available at SSRN: https://ssrn.com/abstract=4926398 or http://dx.doi.org/10.2139/ssrn.4926398 [-PDF-](https://download.ssrn.com/2024/9/9/4926398.pdf?response-content-disposition=inline&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEH4aCXVzLWVhc3QtMSJGMEQCIDILb74QncyuE%2B42i9xf%2BaxvsMECsst7t7uhMbItW73LAiBcnjJzWocv5%2BXlRr%2Fmq4h2z%2FcLz%2B14pFhwnGyh81WW%2ByrGBQjX%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAQaDDMwODQ3NTMwMTI1NyIMNgLD9Vt%2BLZqZWj66KpoFO0KAyg2Wek2gSHmYOsnNH%2F8MszEixWa4Nq7cMglkzJCUR6uAYSFmeV2CQhMpZKP2%2Bahc%2BTwfTOQeMKuFj%2BLkRnt477JIBmFe80Rw56Bw9dFd6vBgbec%2F814fgUS6U%2Fb%2ByuCj6ij%2Bemp6lnfpMoW7geqicd7SrWyW3F7UTwjSRvw6HxUvYmR%2B5TGNz1w8DxHGg7tPBwcNVqf8McuBxFXOngkBVOHRBDGea1cR5lDkhhYj65ZC45UsVd1oVL4VBpGgPMLxrOvV3JvFzlpI4RwxYnylag8dKbXd%2BA6cTubHulW1z658QPYPO8dEKMGeKzvdy3%2FcmQ%2BjwNdmjt7PZIv64I4j9hmdW7S42M8WRxj%2FSO%2B4S%2BLQ8Zgok%2B0lzT4fh8b%2B%2B%2FRsW47S3uA3PltYjZ3qEzw1bBIADrZJJlS%2BYCspDu34Lr9HIwEpjd7%2FixbqOCUmla%2BpWn%2BJvMBbuCx1BGBQ%2BNmLfaHW93ACLeMAJ%2Brzw%2Bt4%2BebL%2B4xoMkDgU30GwRZ0q4%2BYoRBzAHe3aFhXhdn3xDtzjSzCB%2BDhXQMNg2mWYPrJUxuIcTgQABOU99BHzU2KrEThFF8jdY0HEGE8gL5o5Sg845fN0uzEN%2B0QyZyvSM8MkgkXULfMB20JHxdUsKOkClMMYSWHtr%2Fkx%2FXFJmwmp9OKGnWiJYXLE8m55AcRBpNXJXs%2FngtEyMGP0rKbRgIk0yjmqYyzYj6wNr%2B1BsX8oqT%2F%2FqDNXKttXNa4970LsI%2F1YCnlsDCKi7VtWWhqaQwl4Vi7Cgpq%2BAgeZPscapn1kmOHkXZLTB2TPq7JwlVycQSk72rjTSJRbzmExIHllIe83uMIOTmfJiAWYi%2Bzar%2FK0Hcstik6jguowBY4rc65uEnVsdlnvv0jYt5QMIicgL8GOrIBKdJchzbumtXX5xb3f3eDTcxCHSXTB1%2B%2FuIxTniH50E1eCFQ0mvcIuoIn85E1lIvbRIWjyB9LJEfP9rFutg22pDqYBzpb8ha2MbNzGvb0oM4TbY50wbeBtYTyD38v1oQTGNJH0a0FCAWnQNSFdkIIYWc7i75yR33OWrvw2DwvThfZ%2B%2FWtJ6qoPQixlDZnA7tMgmm4rf658mkC3VBP6tyTyFKB6aBACFKD1zjQfU%2BJBBlNTg%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250323T145004Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAUPUUPRWE6TQSXMQN%2F20250323%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=1ef5040c9a576866c6cc92bc11c12b1175dfea662d9557288dc84204f953f0ba&abstractId=4926398)
  - 该文的附录提供了一些 Prompts





# B775：用AI协助生成研究假设：我的三组提示词

- Anna Young, 2024, Blog, I Use These 3 ChatGPT AI Prompts for Crafting Hypotheses, and the Results Blew My Mind!, [-Link-](https://medium.com/@yangyinjuan.zju/i-use-these-3-chatgpt-ai-prompts-for-crafting-hypotheses-and-the-results-blew-my-mind-8fd4cafef55b)
  - 按照作者撰写提示词的思路，写三个中文版本，并分别在 ChatGPT, DeepSeek 和豆包中测试
  - 最终形成一些些提示词的思路和大致要求

## 作者提供的提示词模板

- **Prompt 1**: Adopt the role of an academic researcher in [RESEARCH AREA]. Your task is to plan a clear and concise hypothesis that addresses a specific research question within this area. The hypothesis should be based on existing literature, theories, or frameworks relevant to [RESEARCH AREA]. It must be testable, either through empirical research methods or qualitative analysis, and should contribute to the existing body of knowledge by addressing a gap or challenging an existing assumption. Ensure your hypothesis is specific, measurable, achievable, relevant, and time-bound (SMART). Provide a brief explanation of the rationale behind your hypothesis, linking it to key concepts, theories, or previous studies in the field.
- **Prompt 2**: Determine how more evidence can be integrated into the essay [Insert essay topic] to strengthen the argument [Insert what you wish to prove through the essay].
- **Prompt 3**: Give me the most relevant theories, models, and commonly cited research on the topic [Insert topic name] for writing Hypotheses part of the [Insert what you wish to prove through the essay].



# B774：论文推介：如何利用大语言模型辅助生成因果推断的假设条件

- Cohrs, K.-H., Diaz, E., Sitokonstantinou, V., Varando, G., & Camps-Valls, G. (2025). Large language models for causal hypothesis generation in science. Machine Learning: Science and Technology, 6(1), 013001. [Link](https://doi.org/10.1088/2632-2153/ada47f), [PDF](https://iopscience.iop.org/article/10.1088/2632-2153/ada47f/pdf), [Google](<https://scholar.google.com/scholar?q=Large language models for causal hypothesis generation in science>).

# B773：翻译：大语言模型通俗简介

- Byeungchun Kwon, Taejin Park, Fernando Perez-Cruz and Phurichai Rungcharoenkitkul, 2024, Large language models: a primer for economists, [-Link-](https://www.bis.org/publ/qtrpdf/r_qt2412b.htm), [-PDF-](https://www.bis.org/publ/qtrpdf/r_qt2412b.pdf), [github](https://github.com/bis-med-it/LLM_Primer_for_Economists)


# B772：论文推介：AI与社会科学融合到什么程度了？

- Xu, R., Sun, Y., Ren, M., Guo, S., Pan, R., Lin, H., Sun, L., & Han, X. (2024). AI for social science and social science of AI: A Survey (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2401.11839) (rep), [PDF](https://arxiv.org/pdf/2401.11839.pdf), [Google](<https://scholar.google.com/scholar?q=AI for social science and social science of AI: A Survey (Version 1)>).
  - 介绍了 AI 在社科各个领域的应用情况



# B771：AI能胜任匿名评审工作吗？

从下文中抽取主要观点，进而提供一些使用 AI 来评审自己论文初稿的例子 (主要是收集/自己测试一些有用的 Prompts)

作者在附录中提供了很多 Prompts，可以翻译为中文后在 ChatGPT 中测试一下。

- Liang, W., Zhang, Y., Cao, H., Wang, B., Ding, D. Y., Yang, X., Vodrahalli, K., He, S., Smith, D. S., Yin, Y., Mcfarland, D. A., & Zou, J. (2024). Can Large Language Models Provide Useful Feedback on Research Papers? A Large-Scale Empirical Analysis. NEJM AI, 1(8). [Link](https://doi.org/10.1056/AIoa2400196), [PDF](https://arxiv.org/pdf/2310.01783), [Google](<https://scholar.google.com/scholar?q=Can Large Language Models Provide Useful Feedback on Research Papers? A Large-Scale Empirical Analysis>).

核心观点：
- 通过回顾性和前瞻性评估，我们发现 LLM 反馈与人工反馈之间存在大量重叠，并且用户对 LLM 反馈的实用性持积极看法。尽管人工专家评审应继续成为科学过程的基础，但 LLM 反馈可能会使研究人员受益，尤其是在无法及时获得专家反馈以及稿件准备的早期阶段。
- 总结这篇论文的其他重要观点

如下内容非常实用：
- Supplementary Figure 5. Schematic of the LLM scientific feedback generation system。重点介绍这里提供的 ③ Prompt。

## Prompt 1: sample

```
Your task now is to draft a high-quality review outline for a Nature family journal for a
submission titled <Title>:
‘‘‘
<Paper_content>
‘‘‘

======
Your task:
Compose a high-quality peer review of a paper submitted to a Nature family journal.
Start by "Review outline:".
And then:
"1. Significance and novelty"
"2. Potential reasons for acceptance"
"3. Potential reasons for rejection", List multiple key reasons. For each key reason, use
**>=2 sub bullet points** to further clarify and support your arguments in painstaking
details. Be as specific and detailed as possible.
"4. Suggestions for improvement", List multiple key suggestions. Be as specific and detailed
as possible.
Be thoughtful and constructive. Write Outlines only.
```

# B770：新书推荐：CausalML-book

写一篇推文介绍这本书，包括：
- 简介：作者简介，内容梗概
- 特色：强调 ML 和 AI 在因果推断中的作用，列举书中的内容安排来说明。比如，第一章讲解 OLS 时，重点强调了 FWL 定理，引入了交叉验证等估计方法 (这通常是机器学习课本中重点介绍的内容，传统计量教科书通常不涉及这部分内容)
- 课程配套资料：notebook，R 和 Python 代码支持，参见该书的 [Website](https://causalml-book.org/)


> CausalML-book   

- Chernozhukov, V. & Hansen, C. & Kallus, N. & Spindler, M. & Syrgkanis, V. (**2024**): Applied Causal Inference Powered by ML and AI. CausalML-book.org; arXiv:2403.02467. [-PDF-](https://arxiv.org/pdf/2403.02467)，[Website](https://causalml-book.org/)
  - 该书的 [Website](https://causalml-book.org/) 提供了各章的 PDF，codes Notebook (R and Python)

## 来自大牛的书评

> Joshua Angrist  

![20250324164635](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250324164635.png)

> Judea Pearl  

![20250324164814](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250324164814.png)


# B769：AI 工具推荐

自行搜索资料，整理一份相对完整的适用于学术研究的ai工具清单。

我们这篇推文只整理有关学术研究方面的，至于其他画画啊，生活方面的我们就不要涉及了。

参考资料：
- [全球AI网站汇总](https://github.com/xxxily/hello-ai/blob/main/home/navigation.md)
- [最新免费AI服务网站推荐](https://github.com/xxxily/hello-ai/blob/main/README-zh.md)


# B768：论文推介：如何论证因果关系？

- Garg, P., & Fetzer, T. (2025). Causal Claims in Economics (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2501.06873) (rep), [PDF](https://arxiv.org/pdf/2501.06873.pdf), [Google](<https://scholar.google.com/scholar?q=Causal Claims in Economics (Version 1)>).
  - [Short-Review](https://cepr.org/voxeu/columns/leveraging-large-language-models-large-scale-information-retrieval-economics)

推文重点：
- 各种因果推断方法的应用情况和趋势
- 不同研究主题和关键词的关注趋势
- 其它 (酌情确定)

![20250324154633](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250324154633.png)

> **Figure 4**: Proliferation of Empirical Methods Over Time in NBER and CEPR Working Papers   
> **Note**: This figure shows the proliferation of key empirical methods used in NBER and CEPR working papers over time: Difference-in-Differences (DiD), Instrumental Variables (IV), Randomized Controlled Trials (RCTs), Regression Discontinuity Design (RDD), Two-Way Fixed Effects (TWFE), Structural Estimation, Event Studies, Simulations, and Theoretical/Non-Empirical research. Each panel represents the proportion of papers utilizing one of these methods per year, with the $y$-axis showing the proportion of total papers and the $x$-axis indicating the year of publication. The data covers all NBER and CEPR working papers from 1980 to 2023. DiD has seen a significant increase since the 1980s, rising from around $4 \%$ to over $15 \%$ of papers in recent years, reflecting its growing importance in empirical research. IV methods have also increased steadily from approximately $2 \%$ to over $6 \%$ over the same period. RCTs and RDDs, while starting from near zero in the 1980s, have grown to over $7 \%$ and $2 \%$ respectively in recent years, indicating the rising feasibility and acceptance of experimental and quasi-experimental designs in economics. Conversely, the use of theoretical and non-empirical research has declined significantly, from around $20 \%$ in 1980 to under $10 \%$ in 2023, suggesting a shift towards empirical analysis in the discipline. The use of simulations has decreased from over $6 \%$ in 1980 to around $2-4 \%$ in recent years. These trends highlight the increasing emphasis on credible identification strategies and the evolution of empirical methods in economics.

![20250324154846](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250324154846.png)

> Figure 5: Cross-Sectional Breakdown of Empirical Methods by Field in NBER and CEPR Working
Papers   
> Note: This figure displays the cross-sectional distribution of nine empirical methods-Difference-in-Differences (DiD), Instrumental Variables (IV), Randomized Controlled Trials (RCTs), Regression Discontinuity Design (RDD), Event Studies, Simulations, Structural Estimation, Two-Way Fixed Effects (TWFE), and Theoretical/Non-Empirical research-across twelve fields in NBER and CEPR working papers. Each point represents the proportion of papers within a specific field that utilize a given method, with $95 \%$ confidence intervals depicted by error bars. The fields include Finance, Development, Labour, Public, Urban, Macroeconomics, Behavioral, Economic History, Econometrics, IO, Environmental, and Health. The plot highlights considerable variation in the adoption of empirical methods across fields. DiD is most commonly used in Health, Urban, and Labour, with over $21 \%$ of papers in Health, over $16 \%$ in Urban, and over $13 \%$ in Labour utilizing this method. RCTs are particularly prominent in Behavioral and Development, where they are used in over $20 \%$ and $11 \%$ of papers respectively, reflecting the feasibility of experimental interventions in these areas. Simulations and Structural methods are more prevalent in Macroeconomics and Econometrics, reflecting the need for complex theoretical modeling in these fields. Simulations account for over $6 \%$ of papers in Macroeconomics and over $6 \%$ in Econometrics. Structural methods are used in approximately 6\% of papers in Macroeconomics and over 5\% in Econometrics. Fields like Macroeconomics and Finance rely more on IV methods and simulations, with Macroeconomics having around 3\% of papers using IV methods and over $6 \%$ using simulations. Theoretical and non-empirical research remains significant in fields like Industrial Organization and Macroeconomics, with over $24 \%$ and $17 \%$ of papers respectively. These cross-sectional patterns reflect the methodological preferences specific to the research questions and data availability in each field, underscoring how different areas of economics adopt various empirical strategies to address their unique challenges.

![20250324155133](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250324155133.png)

> Figure 11: Top 5 Rising and Declining Nodes’ Eigenvector Centrality Over Time (Normalized)



# B767：IV：形形色色的 IV

> Wu, A., Kuang, K., Xiong, R., & Wu, F. (2022). Instrumental Variables in Causal Inference and Machine Learning: A Survey (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2212.05778) (rep), [PDF](https://arxiv.org/pdf/2212.05778.pdf), [Google](<https://scholar.google.com/scholar?q=Instrumental Variables in Causal Inference and Machine Learning: A Survey (Version 1)>).

> TABLE 1: Available Codes of Methods for Instrumental Variables and Causal Inference.

|           | IV-based Methods |                                                        |
| :-------: | :--------------: | :----------------------------------------------------: |
|  Method   |     Language     |                          Link                          |
|  DeepIV   |      python      |          https://github.com/jhartford/DeepIV           |
| KernelIV  |      matlab      |           https://github.com/r4hu1-5in9h/KIV           |
|  DualIV   |      matlab      |     https://github.com/krikamol/DualIV-NeurIPS2020     |
|   DFIV    |      python      |      https://github.com/liyuan9988/DeepFeatureIV       |
|  DeepGMM  |      python      |          https://github.com/CausalML/DeepGMM           |
|   AGMM    |      python      |      https://github.com/microsoft/AdversarialGMM       |
|   CBIV    |      python      |             https://github.com/anpwu/CB-IV             |
|  AutoIV   |      python      |          https://github.com/junkunyuan/AutoIV          |
|  econML   |      python      |          https://github.com/microsoft/EconML           |
| CausalDCD |      python      | https://github.com/anpwu/Awesome-Instrumental-Variable |


> 2025/4/5 23:42

# B766：AI助手系列：Paperpal

写一篇推文介绍这个工具。
- https://paperpal.com/
- https://www.editage.com/paperpal

## 要求
- 可以用 google 账号登录
- 可以在 Word 中安装插件
- 主要功能：可以搜索官网介绍文档，在线博客文章，Youtube 视频等资料来写
- 注意：所有写入推文中的内容一定要自己亲自测试过感受过，如果你因为设备或网络的原因不能够亲自测试，你可以邀请你的同学或朋友帮你测试。不能简单的当二道贩子，从别的地方翻译过来插到推文里。

## ChatGPT 给出的介绍

Paperpal 是由开科思（Cactus Communications）推出的一款专为科研人员设计的人工智能学术写作工具。它旨在通过提供语言编辑、文本改写与生成、投稿检查等功能，帮助研究人员提升英文论文的质量和发表成功率。

**主要功能：**

- 语言编辑：提供学术语境下的语言校正建议，检查语法、用词和格式一致性，确保文章表达准确流畅。
- AI 助写：协助作者改写句段、缩减篇幅，并生成投稿信、进度查询邮件等沟通素材，优化写作过程。
- 稿件查重：利用 Turnitin 技术检测文章重复率，标注相似内容，维护学术诚信。
- 投稿检查：根据期刊标准，对稿件进行语言和技术评估，提供改进建议，提升投稿质量。

**使用场景：**

- Paperpal 支持网页版、Word 插件和 Overleaf 插件等多种使用模式，方便用户在不同平台上进行学术写作和编辑。
- Paperpal 的技术内核由开科思独立研发，严格遵守学术出版伦理，确保用户数据的安全性和隐私性。

总体而言，Paperpal 通过集成多种智能功能，致力于为学术写作者提供高效、专业的写作辅助服务。



# B765：文献助手：Research Rabbit

> https://researchrabbitapp.com

介绍这个工具，内容上，覆盖这个视频中的内容：[5 Unbelievably Useful AI Tools For Research in 2025 (better than ChatGPT)](https://www.youtube.com/watch?v=wmQVdzBRnN4)

其他参考资料：

Research platform for discovering and visualizing both literature and scholars.
- [-PDF-](https://www.jcu.edu.au/__data/assets/pdf_file/0008/1958831/Research-Rabbit-Overview.pdf)
- [What is ResearchRabbit?](https://teaching.usask.ca/learning-technology/tools/researchrabbit.php)
- Youtube 视频：
  - [How To Use Research Rabbit - Effortlessly Explore Literature for FREE!](https://www.youtube.com/watch?v=phWqcGcxeE4)
  - [5 Unbelievably Useful AI Tools For Research in 2025 (better than ChatGPT)](https://www.youtube.com/watch?v=wmQVdzBRnN4)



# B764：翻译+改写：写代码的提示词Prompts

- [RimaBuilds/Master-coding-prompts-with-ChatGPT](https://github.com/RimaBuilds/Master-coding-prompts-with-ChatGPT)

**写作建议：**

1. Fork 这个仓库，然后打开 readme.md 的原始文档，复制后进行翻译即可。   
2. 注意：最终的博客文章中，不要包含任何表情符号。你可以使用 DeepSeek 等 AI 工具一次性去除所有表情符号。  
3. 提示词采用引用块格式：
   
   ```md
   > Prompt: xxx`
   ```

5. 你可以借助 AI 进行翻译，但要确保最终的中文版不要太生涩，需要自己改一下。 
6. 你可以酌情扩充或适当删减原文中的内容
7. 注意：务必在推文开头部分采用 「编者按：xxx」方式写明这篇推文的来源，以免引起版权纠纷。参见 刘正清, 2025, [被盯上的 EJ 论文：从被质疑到漂亮反击](https://www.lianxh.cn/details/1552.html)。


# B763：翻译+改写：DEV ChatGPT Prompts

- [PickleBoxer/dev-chatgpt-prompts](https://github.com/PickleBoxer/dev-chatgpt-prompts)

写作建议：

1. Fork 这个仓库，然后打开 readme.md 的原始文档，复制后进行翻译即可。   
2. 注意：最终的博客文章中，不要包含任何表情符号。你可以使用 DeepSeek 等 AI 工具一次性去除所有表情符号。  
3. 提示词采用引用块格式：
   
   ```md
   > Prompt: xxx`
   ```

5. 你可以借助 AI 进行翻译，但要确保最终的中文版不要太生涩，需要自己改一下。 
6. 你可以酌情扩充或适当删减原文中的内容
7. 注意：务必在推文开头部分采用 「编者按：xxx」方式写明这篇推文的来源，以免引起版权纠纷。参见 刘正清, 2025, [被盯上的 EJ 论文：从被质疑到漂亮反击](https://www.lianxh.cn/details/1552.html)。


# B762：如何借助 AI 高效完成文献综述

- 根据 Youtube 视频写一篇推文，介绍用于文献综述的 AI 工具。也可以结合类似视频中的内容。注意：推文中提及的工具一定是自己亲测过的工具。[The fastest way to do your literature review with AI](https://www.youtube.com/watch?v=O60Ha2woAZI)
- 可以酌情搜索其他资料补充进来
- 在写推文之前，务必亲自测一下视频里提到的ai工具。如果你不使用就来写这篇推文，那就属于欺骗，而且你写的时候其实也不会有什么感觉的。在你自己用的过程中有任何的障碍或者是你遇到的一些困难，你应该重点把它写在推文里，因为你如果遇到这些问题，其他第1次使用这个工具的用户也同样会遇到这些问题。
- 你可以进一步根据推文的内容录制一个视频 (15 min 左右)，可以算做一篇新的推文任务。



# B761：编写提示词（Prompt）的10条原则和15个建议

基于如下推文的内容，写一篇推文。当然他说的那些原则和建议也未必适合我们国内的这些用户。因为我们使用的ai工具会有一些限制，当然有一些国产的ai工具也不错。

所以在写作的过程中，你要根据国内的这些ai的特征，自己在搜索一些资料加上自己的一些体验。

你也可以借助ai工具来对下面这篇文章的内容进行翻译，但是翻译完以后你一定要自己手动的改一遍，因为有里边的一些术语是非常生硬的表述上也会显得像机器写的，所以你要适当的调整润色一下。

- Bozkurt, A. (2024). Tell Me Your Prompts and I Will Make Them True: The Alchemy of Prompt Engineering and Generative AI. Open Praxis, 16(2), 111–118. [Link](https://doi.org/10.55982/openpraxis.16.2.661), [PDF](https://openpraxis.org/articles/661/files/660d5a9fa8517.pdf), [Google](<https://scholar.google.com/scholar?q=Tell Me Your Prompts and I Will Make Them True: The Alchemy of Prompt Engineering and Generative AI>).
  - In this regard, this paper introduces 10 principles and 15 strategies that refer to ‘Prompt Engineering for Gen[i]erative AI Framework’ to unleash your prompts and, metaphorically, make your wishes true. 

# B760：ChatGPT助手系列：CClaRA-Causal Claims Research Assistant

> <https://www.causal.claims/cclara-causal-claims-ra>

- Garg, P., & Fetzer, T. (2025). Causal Claims in Economics (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2501.06873) (rep), [PDF](https://arxiv.org/pdf/2501.06873.pdf), [Google](<https://scholar.google.com/scholar?q=Causal Claims in Economics (Version 1)>).

A literature review tool grounded on the knowledge graph.

-   Search for papers by causal claims (`where X causes Y`)
-   Search for paper by concept nodes (e.g., `effects of X, causes of X`)
-   Search by claims made in specific journal (e.g. `the top five`)
-   Search by authors working on specific fields, and so on.

## About CClaRA

CClaRA is a customised GPT-4o model fine-tuned with access to our knowledge graph dataset.
This means each response is based on a combination of ChatGPT -4o 's training data and the corpus.
CClaRA searches across multiple files of structured data, ensuring that every query you make provides accurate and comprehensive results. 

训练语料：6000 多篇 NBER 和 SSRN 的工作论文，以及 Top 5 Journal 中的论文 (具体数字要看一下论文原文中的表述)

Garg, P., & Fetzer, T. (2025). Causal Claims in Economics (Version 1). arXiv. [Link](https://doi.org/10.48550/arXiv.2501.06873) (rep), [PDF](https://arxiv.org/pdf/2501.06873.pdf), [Google](<https://scholar.google.com/scholar?q=Causal Claims in Economics (Version 1)>).
  - [Short-Review](https://cepr.org/voxeu/columns/leveraging-large-language-models-large-scale-information-retrieval-economics)

## How to Use CClaRA

1.  Go to <https://chatgpt.com/g/g-QE4aPgEVQ-cclara> and sign in.

2.  Simply type in your query. 


## Use cases

Here are some common use cases

1.  Exact Cause and Effect Match

    -   Example Prompt: "Find papers where fiscal policy causes economic growth."

    -   This search will look for papers that contain the specified cause-effect relationship and return exact matches, if available.

2.  Cause-only Search

    -   Example Prompt: "Find papers with 'job mobility' as a cause."

    -   When only a cause is specified, the assistant will return all papers that mention this cause, along with a list of effects associated with it.

3.  Effect-only Search

    -   Example Prompt: "Find papers with 'earnings growth' as an effect."

    -   If only an effect is provided, the assistant will list papers where this effect is documented, identifying the variety of causes related to this effect.

4.  Semantic and Related Suggestions

    -   Example Prompt: "Find papers where 'government spending' influences 'GDP growth'."

    -   If an exact match isn't found, the assistant will suggest papers with related terms or semantically similar causal claims, helping to broaden the scope when needed.

5.  Combining Searches with Broadening Queries

    -   Example Prompt: "Find papers where 'education' impacts 'wage growth'."

    -   If too few results are found, the assistant may prompt you to expand the query to include related terms, such as including other measures of education or wage outcomes.

## Our Approach

Leveraging a custom Artificial Intelligence (AI) pipeline, we process vast amounts of text to extract and structure causal relationships. Here's how we build the causal graph:

1.  Data Collection: Gathering a comprehensive corpus of working papers from NBER and CEPR.

2.  AI-Powered Extraction: Using our AI model to identify causal claims, empirical methods, and key economic concepts within each paper.

3.  Standardization of Concepts: Mapping extracted variables to official Journal of Economic Literature (JEL) codes for consistency.

4.  Construction of the Causal Graph: Connecting economic concepts through identified causal relationships to form a detailed causal graph.

5.  Visualization: Creating graphical representations that illustrate how economic ideas are causally linked over time.



# B759：R扩展包介绍：disaggregation: 贝叶斯空间分解模型

Nandi, A. K., Lucas, T. C. D., Arambepola, R., Gething, P., & Weiss, D. J. (2023). disaggregation: An R Package for Bayesian Spatial Disaggregation Modeling. Journal of Statistical Software, 106(11). [Link](https://doi.org/10.18637/jss.v106.i11) (内附附件文档和代码), [PDF](https://www.jstatsoft.org/index.php/jss/article/view/v106i11/4476), [Google](<https://scholar.google.com/scholar?q=disaggregation: An R Package for Bayesian Spatial Disaggregation Modeling>).
- [Paper](https://www.jstatsoft.org/index.php/jss/article/view/v106i11/4476), [R package (disaggregation)](https://www.jstatsoft.org/index.php/jss/article/view/v106i11/4477), [Replication materials](https://www.jstatsoft.org/index.php/jss/article/view/v106i11/4478), [Replication data (mcmc\_out)](https://www.jstatsoft.org/index.php/jss/article/view/v106i11/4479)



# B758：R扩展包介绍：MLGL-层次聚类和Group-Lasso中的相关变量筛选
Grimonprez, Q., Blanck, S., Celisse, A., & Marot, G. (2023). MLGL: An R Package Implementing Correlated Variable Selection by Hierarchical Clustering and Group-Lasso. Journal of Statistical Software, 106(3). [Link](https://doi.org/10.18637/jss.v106.i03) (内附附件文档和代码), [PDF](https://www.jstatsoft.org/index.php/jss/article/view/v106i03/4443), [Google](<https://scholar.google.com/scholar?q=MLGL: An R Package Implementing Correlated Variable Selection by Hierarchical Clustering and Group-Lasso>).


# B757：2025年学术研究的9大最佳AI工具

转：[2025年学术研究的9大最佳AI工具](https://felo.ai/zh-Hant/blog/2025-best-ai-tools-academic-research/)

为了避免抄袭嫌疑，可能你需要在额外收集一些工具。从他这个清单里排除掉3~4个工具，最后形成一个新的标题，比如说 《AI 助力学术研究：推荐 15 AI 工具》

# B756：翻译-Python: Dynamic Double Machine Learning

整合如下讲义，写成 1 篇推文。

- [Dynamic Double Machine Learning](https://econml.azurewebsites.net/spec/estimation/dynamic_dml.html)

可能需要预先阅读如下资料：
- [因果推断：双重机器学习-ddml](https://www.lianxh.cn/details/1221.html)
- [DRL: Doubly Robust Learning](https://econml.azurewebsites.net/spec/estimation/dr.html)
- [DDML: Orthogonal/Double Machine Learning](https://econml.azurewebsites.net/spec/estimation/dml.html#dmluserguide)



# B755：AI-IV：如何借助大语言模型寻找IV？

- 请写一篇推文，介绍文章中提到的方法，并确保通过自己的 AI 工具进行实际测试。
- 最好使用像 Kimi 或者豆包这样的工具，因为它们的提示词和对话过程可以分享。DeepSeek 则无法分享。我个人使用的是 ChatGPT，但因为很多人没有账户，所以如果你分享的结果基于 ChatGPT，别人可能打不开。
- 最好挑选一篇最近一到两年内在国内顶级期刊（如《经济研究》或《管理世界》）上发表的论文，看看其中是否应用了工具变量法。或者，你也可以选择一个当前热门话题，在相关顶级期刊的多篇文章中发现内生性问题，然后尝试使用文章中介绍的方法寻找工具变量。你可以检验一下在这些顶刊文章已经给出的工具变量基础上，是否还能找到额外的有效工具变量。

Han, S. (2024). Mining Causality: AI-Assisted Search for Instrumental Variables (Version 2). arXiv. [Link](https://doi.org/10.48550/arXiv.2409.14202) (rep), [PDF](https://arxiv.org/pdf/2409.14202.pdf), [Google](<https://scholar.google.com/scholar?q=Mining Causality: AI-Assisted Search for Instrumental Variables (Version 2)>).

- 工具变量法（IVs）是因果推断的主流实证策略。寻找工具变量依赖研究者的创造性思维，而论证其有效性（尤其是排除性限制）常需修辞技巧。本文提出利用大语言模型（LLMs）通过叙事和反事实推理搜索新工具变量，其原理类似人类研究过程，但 LLMs 可极大加速搜索并探索海量可能性。我们设计了多步骤角色扮演提示策略，有效模拟经济主体决策逻辑并引导模型处理现实场景。方法应用于教育回报率、供需关系、同伴效应三大经典案例，并扩展至寻找回归 / 双重差分控制变量及断点设计运行变量。

There are at least four benefits to pursuing this AI-assisted approach to discovering IVs. 
- First, researchers can conduct a systematic search at a speedy rate, while adapting to the particularities of their settings. 
- Second, interacting with AI tools can inspire ideas for possible domains for novel IVs. 
- Third, the systematic search could increase the possibility of obtaining multiple IVs, which would then enable formal (i.e., statistical) testing of their validity via over-identifying restrictions. 
- Fourth, having a list of candidate IVs would increase the chances of finding actual data that contain IVs or guide the construction of such data, including the design of experiments to generate IVs.



# B754：R扩展包介绍：sparsegl: An R Package for Estimating Sparse Group Lasso

Liang, X., Cohen, A., Heinsfeld, A. S., Pestilli, F., & Mcdonald, D. J. (2024). sparsegl: An R Package for Estimating Sparse Group Lasso. Journal of Statistical Software, 110(6). [Link](https://doi.org/10.18637/jss.v110.i06) (内附附件文档和代码), [PDF](https://www.jstatsoft.org/index.php/jss/article/view/v110i06/4608), [Google](<https://scholar.google.com/scholar?q=sparsegl: An R Package for Estimating Sparse Group Lasso>).

-  [Paper](https://www.jstatsoft.org/index.php/jss/article/view/v110i06/4608) [R package (sparsegl)](https://www.jstatsoft.org/index.php/jss/article/view/v110i06/4609) [R replication code](https://www.jstatsoft.org/index.php/jss/article/view/v110i06/4610)

# B753：R扩展包介绍：fairadapt: Causal Reasoning for Fair Data Preprocessing
Plecko, D., Bennett, N., & Meinshausen, N. (2024). fairadapt: Causal Reasoning for Fair Data Preprocessing. Journal of Statistical Software, 110(4). [Link](https://doi.org/10.18637/jss.v110.i04) (内附附件文档和代码), [PDF](https://www.jstatsoft.org/index.php/jss/article/view/v110i04/4614), [Google](<https://scholar.google.com/scholar?q=fairadapt: Causal Reasoning for Fair Data Preprocessing>).


# B752：论文推介：安慰剂检验

Eggers, A. C., Tu?ón, G., & Dafoe, A. (**2024**). Placebo Tests for Causal Inference. American Journal of Political Science, 68(3), 1106–1121. Portico. [Link](https://doi.org/10.1111/ajps.12818), [HTML](https://onlinelibrary.wiley.com/doi/full/10.1111/ajps.12818), [PDF](https://onlinelibrary.wiley.com/doi/epdf/10.1111/ajps.12818), [Google](<https://scholar.google.com/scholar?q=Placebo Tests for Causal Inference. American Journal of Political Science, 68(3), 1106–1121>). [-Replication-](https://doi.org/10.7910/DVN/3RR5RJ)

提纲：
- 安慰剂检验在实证分析中的应用趋势
- 何谓安慰剂检验？
- 基本假设
- 典型案例。找几篇论文，简要介绍几种典型的安慰剂检验套路
- Check list
- 小结
  
## Check list

作为总结，我们提供了一份适用于任何安慰剂检验的问题清单。正如"我们能从安慰剂检验中学到什么？"所述，关于安慰剂检验的核心问题是："当某些核心假设以特定方式被违反时，检验结果是否比假设成立时更可能失败？"这个问题可分解为以下检查清单：

1. 检验探测了哪些核心假设——与点估计相关的偏差假设（识别、估计、测量、样本选择）或与标准误相关的分布假设？（见"信息性安慰剂检验的形式条件"）

2. 哪些核心假设的潜在违反情况最为相关？（见"我们能从安慰剂检验中学到什么？"）

3. 构建安慰剂检验时，对核心分析的哪个组成部分（结果变量、处理变量、研究群体）进行了调整？（见"安慰剂检验的分类"）

4. 为何在这种调整下，处理变量应对安慰剂分析中的结果变量无影响？（NATE，见"信息性安慰剂检验的形式条件"）

5. 安慰剂分析与核心分析在哪些方面具有相似性，从而能够检测核心假设的违反？（LVBA/LVDA，见"信息性安慰剂检验的形式条件"）

6. 安慰剂分析是否可能存在核心分析中未出现的假设违反，导致假阳性率上升？（LBA/LDA，见"信息性安慰剂检验的形式条件"）

7. 安慰剂检验是否具备足够的统计精度（如通过标准误判断）来检测核心假设的违反？（见"我们能从安慰剂检验中学到什么？"）

每个问题均标注了正式框架中的对应章节，这些问题也贯穿于"偏差假设的安慰剂检验设计"和"分布假设的安慰剂检验设计"的案例讨论。如果读者在遇到安慰剂检验时能经常自问这些问题，而研究者在报告检验结果时能提供足够的信息来回答它们，那么安慰剂检验将更好地帮助评估应用因果推断中研究设计的可信度。

（注：NATE = 平均处理效应为零；LVBA = 局部效度偏差假设；LVDA = 局部效度分布假设；LBA = 局部偏差假设；LDA = 局部分布假设）


# B751：Judea Pearl 聊 AI 的未来：我们需要因果AI

根据下面的推文，还有视频来整理一篇推文。尽量原汁原味的反映 Pearl 教授的观点。

> Judea Pearl on the Future of AI, LLMs, and Need for Causal Reasoning, [-Link-](https://causalai.causalens.com/resources/blog/judea-pearl-on-the-future-of-ai-llms-and-need-for-causal-reasoning/), [Vedio](https://player.vimeo.com/video/969883388)

<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/969883388?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture; clipboard-write" style="position:absolute;top:0;left:0;width:100%;height:100%;" title="Session 4 CAI SF - A Fireside Chat with Judea Pearl and Darko Matovski"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

>This transcript has been lightly edited for length and clarity.


# B750：遗漏变量？敏感性分析！新命令sensemakr-R codes

此前，连享会已经发布了该命令的 Stata 版本的介绍 (邹恬华, 2021, [遗漏变量？敏感性分析！新命令sensemakr](https://www.lianxh.cn/details/621.html))。这篇推文则提供基于 R codes 的范例。在作者正式发表的版本中，对 R codes 的介绍非常细致，还包含了高级用法以及 Appendix B. Interaction and Bootstrap Example 等例子。

- Cinelli, C., Ferwerda, J., & Hazlett, C. (2024). Sensemakr: Sensitivity Analysis Tools for OLS in R and Stata. Observational Studies, 10(2), 93–127. [Link](https://doi.org/10.1353/obs.2024.a946583), [PDF](https://muse.jhu.edu/pub/56/article/946583/pdf), [Google](<https://scholar.google.com/scholar?q=Sensemakr: Sensitivity Analysis Tools for OLS in R and Stata>).

提纲：
- 敏感性分析的思路、使用背景等
- 基本理论分析
- R 实操
- 进阶应用
- Interaction and Bootstrap Example
- 结论


# B749：敏感性分析：实操手册

Prasad, S. K., Kastel, F., Pande, S., Zhang, C., & Glandon, D. M. (2024). A checklist to guide sensitivity analyses and replications of impact evaluations. Journal of Development Effectiveness, 16(3), 332–348. [Link](https://doi.org/10.1080/19439342.2024.2318695), [PDF](https://www.tandfonline.com/doi/epdf/10.1080/19439342.2024.2318695%4010.1080/tfocoll.2024.0.issue-special-issue-on-tree?needAccess=true), [Google](<https://scholar.google.com/scholar?q=A checklist to guide sensitivity analyses and replications of impact evaluations>). [-Appendix-Word](https://www.tandfonline.com/doi/suppl/10.1080/19439342.2024.2318695%4010.1080/tfocoll.2024.0.issue-special-issue-on-tree?scroll=top)

Note: 
- 这篇论文除了正文的内容以外，附录的内容也不错，但是我还没有细看，你自己读完以后来决定是否把正文和附录的内容合并起来。如果两部分的内容有比较明显的差别，各自都有各自的价值，那就可以把它们拆成两篇推文来写，算两个工作量。
- 我用豆包把 [-Appendix-Word](https://www.tandfonline.com/doi/suppl/10.1080/19439342.2024.2318695%4010.1080/tfocoll.2024.0.issue-special-issue-on-tree?scroll=top) 中的内容转换成了 Markdown 格式，但是里边的参考文献尤其是参考文献的链接没有很好的处理，你可以继续用其他的ai工具来完成这个任务，或者自己使用 [getiref](https://www.lianxh.cn/details/1382.html) 命令来补充进去。


# B748：翻译-IPW - 面板数据因果推断中的逆概率加权

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2020. “Generating Inverse Probability Weights for Marginal Structural Models with Time-Series Cross-Sectional Panel Data.” December 3, 2020. https://doi.org/10.59350/48w1z-xen07.


# B747：翻译-IPW - 二元和连续处理效应的逆概率加权

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2020. “Generating Inverse Probability Weights for Both Binary and Continuous Treatments.” December 1, 2020. https://doi.org/10.59350/1svkc-rkv91.


# B746：翻译-R2 - 韦恩图直观解读

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2021. “Exploring R2 and Regression Variance with Euler/Venn Diagrams.” August 21, 2021. https://doi.org/10.59350/t57vy-p5115.

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。


# B745：翻译：用 R 绘制供给需求曲线

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。

- Heiss, Andrew. 2017. Create supply and demand economics curves with ggplot2. [Link](https://www.andrewheiss.com/blog/2017/09/15/create-supply-and-demand-economics-curves-with-ggplot2/)


# B744：翻译：ATE, ATT, and ATU

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2024. “Demystifying Causal Inference Estimands: ATE, ATT, and ATU.” March 21, 2024. [-Link-](https://www.andrewheiss.com/blog/2024/03/21/demystifying-ate-att-atu/), https://doi.org/10.59350/c9z3a-rcq16.
  - 这篇推文对理解因果推断基本概念，尤其是逆概率加权非常有帮助

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。


# B743：翻译：贝叶斯逆概率加权

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2021. “How to Use Bayesian Propensity Scores and Inverse Probability Weights.” December 18, 2021. [-Link-](https://doi.org/10.59350/nrwsd-3jz20)

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。


# B742：翻译：零膨胀模型 - R 解读

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2022. “A Guide to Modeling Outcomes That Have Lots of Zeros with Bayesian Hurdle Lognormal and Hurdle Gaussian Regression Models.” May 9, 2022. https://doi.org/10.59350/ety2j-09566. [-Link-](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/)

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。


# B741：翻译：被解释变量是比率时如何估计？

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2021. “A Guide to Modeling Proportions with Bayesian Beta and Zero-Inflated Beta Regression Models.” November 8, 2021. https://doi.org/10.59350/7p1a4-0tw75. [-Link-](https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/)

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。

![20250322004357](https://fig-lianxh.oss-cn-shenzhen.aliyuncs.com/20250322004357.png)


# B740：翻译：因果推断之后门法则详解

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- Heiss, Andrew. 2021. “Do-Calculus Adventures! Exploring the Three Rules of Do-Calculus in Plain Language and Deriving the Backdoor Adjustment Formula by Hand.” September 7, 2021. [-Link-](https://doi.org/10.59350/fqkhz-kq526).

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。


# B739：翻译：R 常用数据处理函数可视化解读

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- [Visualizing {dplyr}’s mutate(), summarize(), group_by(), and ungroup() with animations](https://www.andrewheiss.com/blog/2024/04/04/group_by-summarize-ungroup-animations/)

>Note: 点击主页面右上角的 `</> code` 按钮即可复制原文 Markdown 格式文件，在此基础上运行 R 代码，翻译即可。


# B738：quarto 模板介绍

写一篇推文，介绍 Quarto 模版的使用和下载方法。

提供几个可以下载 Quarto 论文或讲义模板的网址，展示其使用方法和效果。例如：
- [Hikmah Quarto templates](https://github.com/andrewheiss/hikmah-academic-quarto)


# B737：全新集成编辑器：Positron

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。

- [Fun with Positron: Combine the best of RStudio and Visual Studio Code in Posit’s new Positron IDE](https://www.andrewheiss.com/blog/2024/07/08/fun-with-positron/)


# B736：翻译 What to do with age? Linear, Discrete, Both, or Spline

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
- <https://arelbundock.com/posts/age_linear_discrete/age_linear_discrete.html>
- 类似于时间趋势和时间虚拟变量那篇。参见此前连享会的推文：
  - 徐婷, 徐云娇, 2020, [傻傻分不清：时间趋势项与时间虚拟变量](https://www.lianxh.cn/details/147.html), 连享会 No.147.
- [What to do with age? (including a regression predictor linearly and also in discrete steps)](https://statmodeling.stat.columbia.edu/2024/06/19/what/)


# B735：翻译+补充-marginalia：边际效应详解

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  

https://www.andrewheiss.com/blog/2022/05/20/marginalia/

如果太长，可以拆成 2-3 篇推文


# B734：G-computation

从 [The causal cookbook: Recipes for propensity scores, g-computation, and doubly robust standardization](https://journals.sagepub.com/doi/abs/10.1177/25152459241236149) 中抽取内容，再借助 DeepSeek，ChatGPT，豆包等工具完成写作。

> **Box 5**. G-Computation Recipe

Ingredients: Action $A$, outcome $Y$, and controls $C$.

Important: For an unbiased estimate, the controls $C$ must be sufficient to achieve conditional exchangeability.

- **Step 1**: Model the outcome as $\mathrm{Q}(\mathrm{A}, \mathrm{C})$, a function of the controls. For example, this could be a logistic regression predicting $Y$ from $A$ and $C$, using all individuals in the sample.
- **Step 2**: Duplicate the initial data set in two counterfactual data sets. In one of them, set $A=1$; in the other one, set $A=0$.
All other variables keep their original values.
- **Step 3**: Apply the function $\mathrm{Q}(\mathrm{A}, \mathrm{C})$ to predict each individual's outcome in the two counterfactual data sets; these are the model-implied potential outcomes $Y^1$ and $Y^0$.
- **Step 4**: Aggregate these potential outcomes (e.g., average across all individuals) and contrast them (e.g., by taking their difference) to arrive at an estimate of the estimand of interest.
  
Examples of R packages implementing this estimator: `marginaleffects`, `RISCA`, `stdReg`.


# B733：翻译+扩充：Equivalence Tests Using marginaleffects

翻译如下推文。
- 可以借助 AI 工具，但务必要自己运行所有代码，确保结果无误。
- 翻译完成以后务必要自己人工校对改写一下，以免整个内容有过于浓郁的机器味。
  
Reproducing the Clark and Golder (2006) Example from Rainey (2014)

- <https://www.carlislerainey.com/blog/2023-08-18-equivalence-tests/>

有关 `marginaleffect` 的更详细的介绍参见：

Arel-Bundock, V., Greifer, N., & Heiss, A. (2024). How to Interpret Statistical Models Using marginaleffects for R and Python. Journal of Statistical Software, 111(9). [Link](https://doi.org/10.18637/jss.v111.i09) (内附复现文档和详细说明), [PDF](https://www.jstatsoft.org/index.php/jss/article/view/v111i09/4641), [Google](<https://scholar.google.com/scholar?q=How to Interpret Statistical Models Using marginaleffects for R and Python>). [marginaleffects.com](https://marginaleffects.com/)



# B732：R语言扩展包：边际效应-marginaleffects

Arel-Bundock, V., Greifer, N., & Heiss, A. (2024). How to Interpret Statistical Models Using marginaleffects for R and Python. Journal of Statistical Software, 111(9). [Link](https://doi.org/10.18637/jss.v111.i09) (内附复现文档和详细说明), [PDF](https://www.jstatsoft.org/index.php/jss/article/view/v111i09/4641), [Google](<https://scholar.google.com/scholar?q=How to Interpret Statistical Models Using marginaleffects for R and Python>). [marginaleffects.com](https://marginaleffects.com/)


# B731：Stata - sumdocx 命令介绍

写一篇推文介绍 `sumdocx` 命令的使用方法。建议使用 Stata 自带的数据集 **nlsw88.dta** 来演示。输出的结果尽量用代码块的方式来呈现，有一些结果如果是以word的形式输出的，可以采用截图来呈现。

帮助文件提供了许多例子，展示了 `sumdocx` 命令的多种灵活用法。我们写这篇推文的目的是为了帮助大家在写论文时，能够直接使用现有代码生成符合期刊格式要求的表格，而不仅仅是介绍命令的基本用法（这部分可以通过帮助文件自学）。我们的价值在于提供实际应用的示范，帮助大家实现期刊格式的输出。

因此，请根据这个思路，调整并优化示例代码，适当增加复杂度，确保输出的表格与我们投稿的期刊格式一致。

> 你可以在 [我的提示词](https://chatgpt.com/share/67f0af5c-4af4-8005-a5ea-d45728e500d8) 基础上做进一步的修改，增加其他方面的提示，不断的完善和优化这篇推文。

下面是ai自动输出的一个推文的初稿，你可以在里边添加一些解释性的文字，尤其重要的是矫正里边的代码是否正确在自己的电脑上运行完以后，把输出的结果插入推文。尤其是一些word表格格式输出的结果一定要采用清晰的截图插入推文。

> [B731-sum2docx.md](https://gitee.com/Stata002/StataSX2018/blob/master/sample/B731-sum2docx.md)

用法：点击「编辑」按钮即可查看原文。 


# B730：Power analyses for interaction effects

- Baranger, D. A., Finsaas, M., Goldstein, B., Vize, C., Lynam, D., & Olino, T. M. (2022). Tutorial: Power analyses for interaction effects in cross-sectional regressions. [Link](https://doi.org/10.31234/osf.io/5ptd7), [PDF](http://sci-hub.ren/10.31234/osf.io/5ptd7), [Google](<https://scholar.google.com/scholar?q=>).
  - Code and material availability Expanded hyperlinks are available in Supplemental Table 1. The InteractionPoweR R package is freely available for download at: 
    - https://cran.r-project.org/web/packages/InteractionPoweR/index.html
    - https://dbaranger.github.io/InteractionPoweR/. 
- Underlying code is available at: https://github.com/dbaranger/InteractionPoweR. 
- The interactive Shiny App for simulations is available at: https://mfinsaas.shinyapps.io/InteractionPoweR/.
-  The interactive Shiny App for analytic power is available at: https://david-baranger.shinyapps.io/InteractionPoweR analytic/. 
-  The R software environment is freely available at: https://www.r-project.org/. 
-  RStudio is freely available at: https://www.rstudio.com/products/rstudio/. The code used in this tutorial is available in the Supplement.


# B729：论文复现及推介：平方项的使用

Lee, C.-C., Yuan, Z., He, Z.-W., & Xiao, F. (2024). Do geopolitical risks always harm energy security? Their non-linear effects and mechanism. Energy Economics, 129, 107245. [Link](https://doi.org/10.1016/j.eneco.2023.107245) (rep), [PDF](https://file-lianxh.oss-cn-shenzhen.aliyuncs.com/Refs/refs_common/Lee_2024_Do_geopolitical_risks_always_harm_energy_security_U_shape.pdf), [Google](<https://scholar.google.com/scholar?q=Do geopolitical risks always harm energy security? Their non-linear effects and mechanism>), [-Replication-](https://ars.els-cdn.com/content/image/1-s2.0-S0140988323007430-mmc1.zip)


# B728：论文推介：Large Language Models and Sentiment Analysis in Financial Markets

Liu, C., Arulappan, A., Naha, R., Mahanti, A., Kamruzzaman, J., & Ra, I.-H. (2024). Large Language Models and Sentiment Analysis in Financial Markets: A Review, Datasets, and Case Study. IEEE Access, 12, 134041–134061. [Link](https://doi.org/10.1109/ACCESS.2024.3445413), [PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10638546), [Google](<https://scholar.google.com/scholar?q=Large Language Models and Sentiment Analysis in Financial Markets: A Review, Datasets, and Case Study>).

开始写作之前请先列一个提纲，然后找我讨论。这篇推文的主要目的是介绍大型模型在文本分析里边的一些主要的方法；如何借助ai工具展开此类的分析，以及文中提到的一些典型的数据库。

推文写作过程中可以借助 ai 工具。

比如，我之前写另外一篇推文时的提示词可以参考：[BGATE 模型：ChatGPT 提示词-论文解读](https://chatgpt.com/share/67f0a7d3-cbcc-8005-857d-bbcfe4e680cd)


# B727：交乘项的中心化问题

How to tell when interaction estimates will benefit from centering.

- Olvera Astivia, O. L., & Kroc, E. (2019). Centering in Multiple Regression Does Not Always Reduce Multicollinearity: How to Tell When Your Estimates Will Not Benefit From Centering. Educational and Psychological Measurement, 79(5), 813–826. [Link](https://doi.org/10.1177/0013164418817801), [PDF](http://sci-hub.ren/10.1177/0013164418817801), [Google](<https://scholar.google.com/scholar?q=Centering in Multiple Regression Does Not Always Reduce Multicollinearity: How to Tell When Your Estimates Will Not Benefit From Centering>).


# B726：DDD综述及应用文献整理

> Olden, A., & M?en, J. (2022). The triple difference estimator. The Econometrics Journal, 25(3), 531–553. [Link](https://doi.org/10.1093/ectj/utac010), [PDF](https://www.liuyanecon.com/wp-content/uploads/OldenMoen-2022.pdf), [Google](<https://scholar.google.com/scholar?q=The triple difference estimator>).

任务说明：
1. 介绍 DDD 的基本思想、适用场景和估计方法
2. 最重要的是：总结 Table A1，梳理出使用 DDD 的经典文献。可以使用 [getiref]() 命令或 DeepSeek, ChatGPT 等 AI 工具辅助生成参考文献信息，格式为：Olden, A., & M?en, J. (2022). The triple difference estimator. The Econometrics Journal, 25(3), 531–553. [Link](https://doi.org/10.1093/ectj/utac010), [PDF](http://sci-hub.ren/10.1093/ectj/utac010), [Google](<https://scholar.google.com/scholar?q=The triple difference estimator>).
3. 如果内容太多，可以拆成两篇推文，算作两个工作任务。 


# B725：论文推介：你到底在估计什么？

Lundberg, I., Johnson, R., & Stewart, B. M. (2021). What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory. American Sociological Review, 86(3), 532–565. [Link](https://doi.org/10.1177/00031224211004187), [PDF](http://sci-hub.ren/10.1177/00031224211004187), [Google](<https://scholar.google.com/scholar?q=What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory>), [-Replication-](https://doi.org/10.7910/DVN/ASGOVU)

- **Abstract**: We make only one point in this article. Every quantitative study must be able to answer the question: what is your estimand? The estimand is the target quantity-the purpose of the statistical analysis. Much attention is already placed on how to do estimation; a similar degree of care should be given to defining the thing we are estimating. We advocate that authors state the central quantity of each analysis-the theoretical estimand-in precise terms that exist outside of any statistical model. In our framework, researchers do three things: (1) set a theoretical estimand, clearly connecting this quantity to theory; (2) link to an empirical estimand, which is informative about the theoretical estimand under some identification assumptions; and
(3) learn from data. Adding precise estimands to research practice expands the space of theoretical questions, clarifies how evidence can speak to those questions, and unlocks new tools for estimation. By grounding all three steps in a precise statement of the target quantity, our framework connects statistical evidence to theory.


# B724：文本分析 - LDA 模型实操建议

基于如下资料，写一篇推文介绍 LDA 模型。文中的一些细节可以借助 DeepSeek，ChatGPT 等工具来补充和完善。 

Kulshrestha, R., 2019, A Beginner’s Guide to Latent Dirichlet Allocation(LDA): A statistical model for discovering the abstract topics aka topic modeling. [-Link-](https://towardsdatascience.com/latent-dirichlet-allocation-lda-9d1cd064ffa2)


# B723-空间计量-莫兰指数-moransi-空间自相关检验

任务：以如下论文为基础，写一篇推文介绍这个检验方法和 stata 的实现。

- Kondo, Keisuke (2025) "Testing for Spatial Autocorrelation in Stata," RIEB Discussion Paper Series No.2025-03. [-PDF-](https://www.rieb.kobe-u.ac.jp/academic/ra/dp/English/DP2025-03.pdf), [github](https://github.com/keisukekondokk/moransi)

## 简介
The `moransi` command computes global and local Moran's *I* statistics in Stata.

简要说明一下前期相关推文：

  - 陈子厚, 2022, [Matlab：莫兰指数的编程实现](https://www.lianxh.cn/details/1085.html), 连享会 No.1085.
  - 陈子厚, 2021, [Stata：面板数据的莫兰指数计算与散点图绘制-xtmoran](https://www.lianxh.cn/details/778.html), 连享会 No.778.
  - 陈振环, 张少鹏, 2021, [Stata空间计量：莫兰指数绘图moranplot命令介绍](https://www.lianxh.cn/details/729.html), 连享会 No.729.
 
## Stata 实操
### SSC 安装

```stata
ssc install moransi, replace all

shellout moransi.pdf  // PDF 原文

help moransi
```

### Demo Files

See three applied examples in [`demo`](https://github.com/keisukekondokk/moransi/blob/main/demo) directory.

```
.
|-- columbus //Stata replication code and data
|-- japan\_mesh\_pop //Stata replication code and data
|-- japan\_muni\_unemp //Stata replication code and data
```

## Reference

- Kondo, Keisuke (2018) "MORANSI: Stata module to compute Moran's *I*," Statistical Software Components S458473, Boston College Department of Economics.
URL: <https://ideas.repec.org/c/boc/bocode/s458473.html>
- Kondo, Keisuke (2025) "Testing for Spatial Autocorrelation in Stata," RIEB Discussion Paper Series No.2025-03.
URL: <https://www.rieb.kobe-u.ac.jp/academic/ra/dp/English/DP2025-03.pdf>


# B722-翻译-论文推介：实证分析常见错误指南

- Wulff, J. N., Sajons, G. B., Pogrebna, G., Lonati, S., Bastardoz, N., Banks, G. C., & Antonakis, J. (2023). Common methodological mistakes. The Leadership Quarterly, 34(1), 101677. [Link](https://doi.org/10.1016/j.leaqua.2023.101677), [PDF](http://sci-hub.ren/10.1016/j.leaqua.2023.101677), [Google](<https://scholar.google.com/scholar?q=Common methodological mistakes>).

写作要点：
- 第一篇推文：整理 Table 1: Common Issues in Empirical Articles and Suggested Solutions. 我已经整理成 items 形式，并使用 ChatGPT 进行了翻译，你可以酌情调整即可。
  - [Table1-英文版](https://gitee.com/Stata002/StataSX2018/blob/master/sample/B722-Common-mistakes.md) | [Table1-中文版](https://gitee.com/Stata002/StataSX2018/blob/master/sample/B722-Common-mistakes-Chinese.md)
- 第二篇推文：对这篇论文的后半部分进行翻译。这些内容为实证分析中的常见错误都提供了解决方法。你可以借助ai的工具进行翻译，我发现一个简单的办法就是你直接把作者原始提供的 pdf 文件的截图给DeepSeek 或者是 ChatGPT，他就可以一页一页的帮你翻译完了。当然你如果能找到更好的办法，那也行。要注意的是，如果你直接把整个pdf传给ai，他会帮你删掉很多内容。